{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our wordlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import all of our wordlists and add them to an array which me can merge at the end. \n",
    "\n",
    "This wordlists should not be filtered at this point. However they should all contain the same columns to make merging easier for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordlists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the dictionary from http://www.dict.cc/?s=about%3Awordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the first 20 lines of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DE-EN vocabulary database\tcompiled by dict.cc\r\n",
      "# Date and time\t2016-08-29 23:46\r\n",
      "# License\tTHIS WORK IS PROTECTED BY INTERNATIONAL COPYRIGHT LAWS!\r\n",
      "# License\tPrivate use is allowed as long as the data, or parts of it, are not published or given away.\r\n",
      "# License\tBy using this file, you agree to be bound to the Terms of Use published at the following URL:  \r\n",
      "# License\thttp://www.dict.cc/translation_file_request.php\r\n",
      "# Contains data from\thttp://dict.tu-chemnitz.de/ with friendly permission by Frank Richter, TU Chemnitz \r\n",
      "# Brought to you by\tPaul Hemetsberger and the users of http://www.dict.cc/, 2002 - 2016\r\n",
      "\r\n",
      "&#945;-Keratin {n}\t&#945;-keratin\tnoun\r\n",
      "&#945;-Lactalbumin {n} <&#945;-La>\t&#945;-lactalbumin <&#945;-La>\tnoun\r\n",
      "&#946;-Mercaptoethanol {n}\t&#946;-mercaptoethanol\tnoun\r\n",
      "&#963;-Algebra {f}\t&#963;-field\tnoun\r\n",
      "&#963;-Algebra {f}\tsigma algebra\tnoun\r\n",
      "& Co.\tand company <& Co.>\t\r\n",
      "'Die' heißt mein Unterrock, und 'der' hängt im Schrank. [regional] [Satz, mit dem Kinder gerügt werden, die von einer (anwesenden) Frau mit 'die' sprechen]\t'She' is the cat's mother. [used to encourage children to use names instead of pronouns to refer to females to whom they should show respect]\t\r\n",
      "'n Abend allerseits! [ugs.]\tEvening all! [coll.]\t\r\n",
      "'nauf [regional] [hinauf]\tup\tadv\r\n",
      "'Nduja {f} [auch: Nduja]\t'nduja [also: nduja]\tnoun\r\n",
      "'ne Macke haben [ugs.]\tto be off one's head [coll.]\tverb\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 20 de-en.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use pandas library to import csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "dictcc_df = pd.read_csv(\"de-en.txt\", \n",
    "                        sep='\\t',\n",
    "                        skiprows=8,\n",
    "                        header=None, \n",
    "                        names=[\"GermanWord\",\"Word\",\"WordType\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview a few entries of the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GermanWord</th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>(aktiv) Werbung machen für</td>\n",
       "      <td>to tout</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>(aktive) Langzeitverbindung {f} [Standverbindu...</td>\n",
       "      <td>nailed-up connection &lt;NUC&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>(aktuelles) Zeitgeschehen {n}</td>\n",
       "      <td>current events {pl}</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>(akustisch) verstehen</td>\n",
       "      <td>to hear</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>(akustische) Haarzelle {f}</td>\n",
       "      <td>auditory cell</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(akustischer) Dissipationsgrad {m}</td>\n",
       "      <td>(acoustic) dissipation factor</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>(akute) Rückenmuskelnekrose {f}</td>\n",
       "      <td>(acute) back muscle necrosis</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(akuter) Hörsturz {m}</td>\n",
       "      <td>acute hearing loss</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(akuter) Myokardinfarkt {m} &lt;AMI / MI&gt;</td>\n",
       "      <td>(acute) myocardial infarction &lt;AMI / MI&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>(akutes) Lungenversagen {n}</td>\n",
       "      <td>acute respiratory distress syndrome &lt;ARDS&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           GermanWord  \\\n",
       "90                         (aktiv) Werbung machen für   \n",
       "91  (aktive) Langzeitverbindung {f} [Standverbindu...   \n",
       "92                      (aktuelles) Zeitgeschehen {n}   \n",
       "93                              (akustisch) verstehen   \n",
       "94                         (akustische) Haarzelle {f}   \n",
       "95                 (akustischer) Dissipationsgrad {m}   \n",
       "96                    (akute) Rückenmuskelnekrose {f}   \n",
       "97                              (akuter) Hörsturz {m}   \n",
       "98             (akuter) Myokardinfarkt {m} <AMI / MI>   \n",
       "99                        (akutes) Lungenversagen {n}   \n",
       "\n",
       "                                          Word WordType  \n",
       "90                                     to tout     verb  \n",
       "91                  nailed-up connection <NUC>     noun  \n",
       "92                         current events {pl}     noun  \n",
       "93                                     to hear     verb  \n",
       "94                               auditory cell     noun  \n",
       "95               (acoustic) dissipation factor     noun  \n",
       "96                (acute) back muscle necrosis     noun  \n",
       "97                          acute hearing loss     noun  \n",
       "98    (acute) myocardial infarction <AMI / MI>     noun  \n",
       "99  acute respiratory distress syndrome <ARDS>     noun  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictcc_df[90:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We only need \"Word\" and \"WordType\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictcc_df = dictcc_df[[\"Word\", \"WordType\"]][:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert WordType Column to a pandas.Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word          object\n",
       "WordType    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_types = dictcc_df[\"WordType\"].astype('category')\n",
    "dictcc_df[\"WordType\"] = word_types\n",
    "# show data types of each column in the dataframe\n",
    "dictcc_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the current distribution of word types in dictcc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noun          759619\n",
       "verb          126806\n",
       "adj            94507\n",
       "adv            26277\n",
       "adj past-p     12519\n",
       "Name: WordType, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictcc_df[\"WordType\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add dictcc corpus to our wordlists array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlists.append(dictcc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the corpus from http://icon.shef.ac.uk/Moby/mpos.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform some basic cleanup on the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the readme file in `nltk/corpora/moby/mpos` gives some information on how to parse the file\n",
    "\n",
    "result = []\n",
    "# replace all DOS line endings '\\r' with newlines then change encoding to UTF8\n",
    "moby_words = !cat nltk/corpora/moby/mpos/mobyposi.i | iconv --from-code=ISO88591 --to-code=UTF8 | tr -s '\\r' '\\n' | tr -s '×' '/'\n",
    "result.extend(moby_words)\n",
    "moby_df = pd.DataFrame(data = result, columns = ['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-D/AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4-F/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4-H'er/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-H/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A battery/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a bon march/v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a cappella/Av</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a capriccio/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a datu/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a fortiori/v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a gogo/Av</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A horizon/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a la carte/Av</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a la king/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a la mode/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a la/P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A level/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a posteriori/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a priori/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a punta d'arco/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a quo/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a rivederci/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A supply/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a tempo/Avh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>a tergo/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a vinculo matrimonii/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>a vol/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>a'/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A-1/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A-axis/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233326</th>\n",
       "      <td>Zworykin/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233327</th>\n",
       "      <td>zygapophysis/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233328</th>\n",
       "      <td>zygodactyl/AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233329</th>\n",
       "      <td>zygomatic arch/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233330</th>\n",
       "      <td>zygomatic bone/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233331</th>\n",
       "      <td>zygomatic process/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233332</th>\n",
       "      <td>zygoma/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233333</th>\n",
       "      <td>zygomorphic/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233334</th>\n",
       "      <td>zygophyllaceous/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233335</th>\n",
       "      <td>zygophyte/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233336</th>\n",
       "      <td>zygosis/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233337</th>\n",
       "      <td>zygospore/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233338</th>\n",
       "      <td>zygotene/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233339</th>\n",
       "      <td>zygote/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233340</th>\n",
       "      <td>zymase/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233341</th>\n",
       "      <td>zymogenesis/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233342</th>\n",
       "      <td>zymogenic/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233343</th>\n",
       "      <td>zymogen/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233344</th>\n",
       "      <td>zymology/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233345</th>\n",
       "      <td>zymolysis/NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233346</th>\n",
       "      <td>zymometer/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233347</th>\n",
       "      <td>zymosis/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233348</th>\n",
       "      <td>Zyrian/NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233349</th>\n",
       "      <td>Zysk/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233350</th>\n",
       "      <td>zZt/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233351</th>\n",
       "      <td>Zz/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233352</th>\n",
       "      <td>ZZ/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233353</th>\n",
       "      <td>Zllner/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233354</th>\n",
       "      <td>Z/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233355</th>\n",
       "      <td>z/N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233356 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Word\n",
       "0                       3-D/AN\n",
       "1                        4-F/N\n",
       "2                     4-H'er/N\n",
       "3                        4-H/A\n",
       "4                  A battery/h\n",
       "5                a bon march/v\n",
       "6                a cappella/Av\n",
       "7                a capriccio/h\n",
       "8                     a datu/h\n",
       "9                 a fortiori/v\n",
       "10                   a gogo/Av\n",
       "11                 A horizon/h\n",
       "12               a la carte/Av\n",
       "13                 a la king/A\n",
       "14                 a la mode/A\n",
       "15                      a la/P\n",
       "16                   A level/h\n",
       "17              a posteriori/A\n",
       "18                  a priori/A\n",
       "19            a punta d'arco/h\n",
       "20                     a quo/h\n",
       "21               a rivederci/h\n",
       "22                  A supply/h\n",
       "23                 a tempo/Avh\n",
       "24                   a tergo/h\n",
       "25      a vinculo matrimonii/h\n",
       "26                     a vol/h\n",
       "27                        a'/A\n",
       "28                       A-1/N\n",
       "29                    A-axis/N\n",
       "...                        ...\n",
       "233326              Zworykin/N\n",
       "233327          zygapophysis/N\n",
       "233328           zygodactyl/AN\n",
       "233329        zygomatic arch/h\n",
       "233330        zygomatic bone/h\n",
       "233331     zygomatic process/h\n",
       "233332                zygoma/N\n",
       "233333           zygomorphic/A\n",
       "233334       zygophyllaceous/A\n",
       "233335             zygophyte/N\n",
       "233336               zygosis/N\n",
       "233337             zygospore/N\n",
       "233338              zygotene/N\n",
       "233339                zygote/N\n",
       "233340                zymase/N\n",
       "233341           zymogenesis/N\n",
       "233342             zymogenic/A\n",
       "233343               zymogen/N\n",
       "233344              zymology/N\n",
       "233345            zymolysis/NA\n",
       "233346             zymometer/N\n",
       "233347               zymosis/N\n",
       "233348               Zyrian/NA\n",
       "233349                  Zysk/N\n",
       "233350                   zZt/N\n",
       "233351                    Zz/N\n",
       "233352                    ZZ/N\n",
       "233353               Zllner/N\n",
       "233354                     Z/N\n",
       "233355                     z/N\n",
       "\n",
       "[233356 rows x 1 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sort out the nouns, verbs and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matches nouns\n",
    "nouns = moby_df[moby_df[\"Word\"].str.contains('/[Np]$')].copy()\n",
    "nouns[\"WordType\"] = \"noun\"\n",
    "# Matches verbs\n",
    "verbs = moby_df[moby_df[\"Word\"].str.contains('/[Vti]$')].copy()\n",
    "verbs[\"WordType\"] = \"verb\"\n",
    "# Magtches adjectives\n",
    "adjectives = moby_df[moby_df[\"Word\"].str.contains('/A$')].copy()\n",
    "adjectives[\"WordType\"] = \"adj\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove the trailing stuff and concatenate the nouns, verbs and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nouns[\"Word\"] = nouns[\"Word\"].str.replace(r'/N$','')\n",
    "verbs[\"Word\"] = verbs[\"Word\"].str.replace(r'/[Vti]$','')\n",
    "adjectives[\"Word\"] = adjectives[\"Word\"].str.replace(r'/A$','')\n",
    "# Merge nouns, verbs and adjectives into one dataframe\n",
    "moby_df = pd.concat([nouns,verbs,adjectives])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add moby corpus to wordlists array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlists.append(moby_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brown (from nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- We can probably work with `nltk.corpus.brown.tagged_words()` when creating our dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all wordlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1277915</td>\n",
       "      <td>1203402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>923477</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>depression</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>36</td>\n",
       "      <td>867851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word WordType\n",
       "count      1277915  1203402\n",
       "unique      923477       62\n",
       "top     depression     noun\n",
       "freq            36   867851"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = pd.concat(wordlists)\n",
    "wordlist.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for results that we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove words that contain non word characters (whitespace, hypens, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>326484</td>\n",
       "      <td>324632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>166915</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>depression</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>36</td>\n",
       "      <td>188966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word WordType\n",
       "count       326484   324632\n",
       "unique      166915       40\n",
       "top     depression     noun\n",
       "freq            36   188966"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we choose [a-z] here and not [A-Za-z] because we do _not_\n",
    "# want to match words starting with uppercase characters.\n",
    "word_chars = r'^[a-z]+$'\n",
    "is_word_chars = wordlist[\"Word\"].str.contains(word_chars, na=False)\n",
    "wordlist_filtered = wordlist[is_word_chars]\n",
    "wordlist_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  We want results that are less than 'x' letters long (x+3 for verbs since they are in their infinitive form in the dictcc wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139647</td>\n",
       "      <td>138790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>59722</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>boom</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>35</td>\n",
       "      <td>88092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word WordType\n",
       "count   139647   138790\n",
       "unique   59722       38\n",
       "top       boom     noun\n",
       "freq        35    88092"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_x_letters = (wordlist_filtered[\"Word\"].str.len() < 9) |\\\n",
    "               ((wordlist_filtered[\"Word\"].str.contains('^to\\s\\w+\\s')) &\\\n",
    "                (wordlist_filtered[\"Word\"].str.len() < 11)\\\n",
    "               )\n",
    "wordlist_filtered = wordlist_filtered[lt_x_letters]\n",
    "wordlist_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove all duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59722</td>\n",
       "      <td>59244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>59722</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>brogue</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>37176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word WordType\n",
       "count    59722    59244\n",
       "unique   59722       26\n",
       "top     brogue     noun\n",
       "freq         1    37176"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist_filtered = wordlist_filtered.drop_duplicates(\"Word\")\n",
    "wordlist_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove words that are difficult to spell\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Words with uncommon vowel duplicates (examples: [\"piing\", \"reeject\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove all names and animals\n",
    "\n",
    "TODO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- We want to remove stopwords from wordlist\n",
    "\n",
    "```\n",
    "from nltk.corpus import stopwords\n",
    "dif = set(wordlist_filtered['Word']) - set(stopwords.words('english'))\n",
    "names = nltk.corpus.names\n",
    "names.fileids()\n",
    "```\n",
    "\n",
    "- We want to remove homonyms that are used in different parts of speech (example: saw (as verb) and saw (as noun))\n",
    "\n",
    "- We want to remove arcane and unusual words\n",
    "\n",
    "```\n",
    "import nltk\n",
    "\n",
    "def unusual_words(text):\n",
    "    text_vocab = set(w.lower() for w in text if w.isalpha())\n",
    "    english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "    unusual = text_vocab - english_vocab\n",
    "    return sorted(unusual)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximize distance between neighbouring words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nouns like \"cobra\" and \"domra\" should not be located at Geo-Coordinate \"55°x11°\" and \"55°x12°\"\n",
    "- TODO: the spread_words() method doesn't actually solve this problem. We will need to update it by calculating the distance to **all 8** of its adjacent neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# `pip install python-levenshtein`\n",
    "# used to calculate the Levenshtein distance between words\n",
    "import Levenshtein as lev\n",
    "\n",
    "# Maximize the Levenshtein distance between neighbouring words\n",
    "def spread_words(dataframe_values, min_distance = 25, min_lev = 5):\n",
    "    words = []\n",
    "    words.extend(dataframe_values)\n",
    "    short_distances = 0\n",
    "    for i in range(len(words)-1):\n",
    "        next = i + 1\n",
    "        if lev.distance(words[i],words[next]) < min_lev:\n",
    "            short_distances = short_distances + 1\n",
    "            words.append(words[next])\n",
    "            words.remove(words[next])\n",
    "    # The value for min_distance was derived\n",
    "    # by simple trial and error\n",
    "    if short_distances < min_distance:\n",
    "        # The remaining words with short distance \n",
    "        # will have to be sorted out by hand.\n",
    "        return words\n",
    "    else:\n",
    "        # Recurse until we minimize short distances\n",
    "        # as much as possible.\n",
    "        return spread_words(words)\n",
    "\n",
    "# Insert distance of neighbour\n",
    "def insert_neighbour_distance(words):\n",
    "    result = []\n",
    "    word_with_neighbour_distance = ()\n",
    "    for i in range(len(words)-1):\n",
    "        next = i + 1\n",
    "        lev_distance = lev.distance(words[i],words[next])\n",
    "        word_with_neighbour_distance = words[i], lev_distance\n",
    "        result.append(word_with_neighbour_distance)\n",
    "    return pd.DataFrame(data = result, columns=['Words', 'NeighbourDistance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>NeighbourDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>canaster</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>torsion</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fiesta</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unfolder</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>renegade</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exaction</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>manism</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>burse</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>punner</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>toolbar</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  NeighbourDistance\n",
       "0  canaster                  7\n",
       "1   torsion                  6\n",
       "2    fiesta                  7\n",
       "3  unfolder                  6\n",
       "4  renegade                  8\n",
       "5  exaction                  6\n",
       "6    manism                  5\n",
       "7     burse                  4\n",
       "8    punner                  6\n",
       "9   toolbar                  7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = wordlist_filtered[wordlist_filtered[\"WordType\"] == \"noun\"]\n",
    "# randomize for better performance\n",
    "nouns = nouns.sample(len(nouns))\n",
    "min_distance_nouns = spread_words(nouns[\"Word\"].values,50,3)\n",
    "nouns_ready_for_export = insert_neighbour_distance(min_distance_nouns)\n",
    "nouns_ready_for_export[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>NeighbourDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>canaster</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>torsion</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fiesta</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unfolder</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>renegade</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exaction</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>manism</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>burse</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>punner</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>toolbar</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  NeighbourDistance\n",
       "0  canaster                  7\n",
       "1   torsion                  6\n",
       "2    fiesta                  7\n",
       "3  unfolder                  6\n",
       "4  renegade                  8\n",
       "5  exaction                  6\n",
       "6    manism                  5\n",
       "7     burse                  4\n",
       "8    punner                  6\n",
       "9   toolbar                  7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjectives = wordlist_filtered[wordlist_filtered[\"WordType\"] == \"adj\"]\n",
    "# randomize for better performance\n",
    "adjectives = adjectives.sample(len(adjectives))\n",
    "min_distance_adjectives = spread_words(nouns[\"Word\"].values,50,3)\n",
    "adjectives_ready_for_export = insert_neighbour_distance(min_distance_adjectives)\n",
    "adjectives_ready_for_export[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>NeighbourDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outlearn</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barraged</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outmove</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unclasp</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sculpsit</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>consoled</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>succumb</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>scythed</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>regrind</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oppress</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  NeighbourDistance\n",
       "0  outlearn                  8\n",
       "1  barraged                  7\n",
       "2   outmove                  7\n",
       "3   unclasp                  6\n",
       "4  sculpsit                  8\n",
       "5  consoled                  8\n",
       "6   succumb                  6\n",
       "7   scythed                  6\n",
       "8   regrind                  6\n",
       "9   oppress                  7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use \"adj past-p\" as verbs conjugated in the past tense until \n",
    "# we use nltk to properly conjugate all verbs in our wordlist\n",
    "verbs_init = wordlist_filtered[((wordlist_filtered[\"WordType\"] == \"adj past-p\") | (wordlist_filtered[\"WordType\"] == \"verb\"))]\n",
    "verbs = verbs_init.sample(n=len(verbs_init))\n",
    "min_distance_verbs = spread_words(verbs[\"Word\"].values,50,3)\n",
    "verbs_ready_for_export = insert_neighbour_distance(min_distance_verbs)\n",
    "verbs_ready_for_export[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the distribution of word types after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noun          37176\n",
       "adj           12177\n",
       "verb           4913\n",
       "adj past-p     2126\n",
       "adv            1232\n",
       "Name: WordType, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist_filtered[\"WordType\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export our filtered word lists to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nouns_ready_for_export.to_csv(\"nouns.csv\", index=False)\n",
    "adjectives_ready_for_export.to_csv(\"adjectives.csv\", index=False)\n",
    "verbs_ready_for_export.to_csv(\"verbs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snoot concaved pian twines\n"
     ]
    }
   ],
   "source": [
    "print(nouns_ready_for_export.sample()['Words'].values[0] + ' ' +\\\n",
    "      verbs_ready_for_export.sample()['Words'].values[0] + ' ' +\\\n",
    "      adjectives_ready_for_export.sample()['Words'].values[0] + ' ' +\\\n",
    "      nouns_ready_for_export.sample()['Words'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 24716),\n",
       " ('VERB', 12971),\n",
       " ('ADP', 12288),\n",
       " ('.', 11928),\n",
       " ('DET', 11387),\n",
       " ('ADJ', 5282),\n",
       " ('ADV', 2953),\n",
       " ('CONJ', 2717),\n",
       " ('PRON', 2514),\n",
       " ('PRT', 2263),\n",
       " ('NUM', 2149),\n",
       " ('X', 86)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged if len(word) < 9)\n",
    "tag_fd.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wsj = nltk.corpus.treebank.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfd2 = nltk.ConditionalFreqDist(wsj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfd1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-f136e08dfaed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# does it appear most often?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcfd1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconditions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'VBD'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcfd1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'VBN'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcfd1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0midx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwsj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'followed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VBN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mwsj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cfd1' is not defined"
     ]
    }
   ],
   "source": [
    "# given that we have word 'foobar' with which tag\n",
    "# does it appear most often?\n",
    "\n",
    "[word for word in cfd1.conditions() if 'VBD' in cfd1[word] and 'VBN' in cfd1[word]]\n",
    "idx1 = wsj.index(('followed', 'VBN'))\n",
    "wsj[idx1-4:idx1+4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "past_participles = [w for w in cfd2 if 'VBN' in cfd2[w]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Show common words for particular parts-of-speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_common_words(tagged_text):\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text)\n",
    "    return dict((tag, cfd[tag].most_common()) for tag in cfd.conditions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 1547),\n",
       " ('man', 1144),\n",
       " ('Af', 990),\n",
       " ('way', 882),\n",
       " ('world', 682),\n",
       " ('life', 673),\n",
       " ('year', 641),\n",
       " ('day', 623),\n",
       " ('work', 571),\n",
       " ('state', 519)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagdict = find_common_words(nltk.corpus.brown.tagged_words())\n",
    "# only nouns (that is, don't include proper nouns)\n",
    "tagdict['NN'][:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
