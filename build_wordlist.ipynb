{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our wordlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import all of our wordlists and add them to an array which me can merge at the end. \n",
    "\n",
    "This wordlists should not be filtered at this point. However they should all contain the same columns to make merging easier for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordlists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the dictionary from http://www.dict.cc/?s=about%3Awordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the first 20 lines of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DE-EN vocabulary database\tcompiled by dict.cc\r\n",
      "# Date and time\t2016-08-29 23:46\r\n",
      "# License\tTHIS WORK IS PROTECTED BY INTERNATIONAL COPYRIGHT LAWS!\r\n",
      "# License\tPrivate use is allowed as long as the data, or parts of it, are not published or given away.\r\n",
      "# License\tBy using this file, you agree to be bound to the Terms of Use published at the following URL:  \r\n",
      "# License\thttp://www.dict.cc/translation_file_request.php\r\n",
      "# Contains data from\thttp://dict.tu-chemnitz.de/ with friendly permission by Frank Richter, TU Chemnitz \r\n",
      "# Brought to you by\tPaul Hemetsberger and the users of http://www.dict.cc/, 2002 - 2016\r\n",
      "\r\n",
      "&#945;-Keratin {n}\t&#945;-keratin\tnoun\r\n",
      "&#945;-Lactalbumin {n} <&#945;-La>\t&#945;-lactalbumin <&#945;-La>\tnoun\r\n",
      "&#946;-Mercaptoethanol {n}\t&#946;-mercaptoethanol\tnoun\r\n",
      "&#963;-Algebra {f}\t&#963;-field\tnoun\r\n",
      "&#963;-Algebra {f}\tsigma algebra\tnoun\r\n",
      "& Co.\tand company <& Co.>\t\r\n",
      "'Die' heißt mein Unterrock, und 'der' hängt im Schrank. [regional] [Satz, mit dem Kinder gerügt werden, die von einer (anwesenden) Frau mit 'die' sprechen]\t'She' is the cat's mother. [used to encourage children to use names instead of pronouns to refer to females to whom they should show respect]\t\r\n",
      "'n Abend allerseits! [ugs.]\tEvening all! [coll.]\t\r\n",
      "'nauf [regional] [hinauf]\tup\tadv\r\n",
      "'Nduja {f} [auch: Nduja]\t'nduja [also: nduja]\tnoun\r\n",
      "'ne Macke haben [ugs.]\tto be off one's head [coll.]\tverb\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 20 de-en.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use pandas library to import csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "dictcc_df = pd.read_csv(\"de-en.txt\", \n",
    "                        sep='\\t',\n",
    "                        skiprows=8,\n",
    "                        header=None, \n",
    "                        names=[\"GermanWord\",\"Word\",\"WordType\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview a few entries of the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GermanWord</th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>(aktiv) Werbung machen für</td>\n",
       "      <td>to tout</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>(aktive) Langzeitverbindung {f} [Standverbindu...</td>\n",
       "      <td>nailed-up connection &lt;NUC&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>(aktuelles) Zeitgeschehen {n}</td>\n",
       "      <td>current events {pl}</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>(akustisch) verstehen</td>\n",
       "      <td>to hear</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>(akustische) Haarzelle {f}</td>\n",
       "      <td>auditory cell</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(akustischer) Dissipationsgrad {m}</td>\n",
       "      <td>(acoustic) dissipation factor</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>(akute) Rückenmuskelnekrose {f}</td>\n",
       "      <td>(acute) back muscle necrosis</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(akuter) Hörsturz {m}</td>\n",
       "      <td>acute hearing loss</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(akuter) Myokardinfarkt {m} &lt;AMI / MI&gt;</td>\n",
       "      <td>(acute) myocardial infarction &lt;AMI / MI&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>(akutes) Lungenversagen {n}</td>\n",
       "      <td>acute respiratory distress syndrome &lt;ARDS&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           GermanWord  \\\n",
       "90                         (aktiv) Werbung machen für   \n",
       "91  (aktive) Langzeitverbindung {f} [Standverbindu...   \n",
       "92                      (aktuelles) Zeitgeschehen {n}   \n",
       "93                              (akustisch) verstehen   \n",
       "94                         (akustische) Haarzelle {f}   \n",
       "95                 (akustischer) Dissipationsgrad {m}   \n",
       "96                    (akute) Rückenmuskelnekrose {f}   \n",
       "97                              (akuter) Hörsturz {m}   \n",
       "98             (akuter) Myokardinfarkt {m} <AMI / MI>   \n",
       "99                        (akutes) Lungenversagen {n}   \n",
       "\n",
       "                                          Word WordType  \n",
       "90                                     to tout     verb  \n",
       "91                  nailed-up connection <NUC>     noun  \n",
       "92                         current events {pl}     noun  \n",
       "93                                     to hear     verb  \n",
       "94                               auditory cell     noun  \n",
       "95               (acoustic) dissipation factor     noun  \n",
       "96                (acute) back muscle necrosis     noun  \n",
       "97                          acute hearing loss     noun  \n",
       "98    (acute) myocardial infarction <AMI / MI>     noun  \n",
       "99  acute respiratory distress syndrome <ARDS>     noun  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictcc_df[90:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We only need \"Word\" and \"WordType\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictcc_df = dictcc_df[[\"Word\", \"WordType\"]][:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert WordType Column to a pandas.Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word          object\n",
       "WordType    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_types = dictcc_df[\"WordType\"].astype('category')\n",
    "dictcc_df[\"WordType\"] = word_types\n",
    "# show data types of each column in the dataframe\n",
    "dictcc_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the current distribution of word types in dictcc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN          759619\n",
       "VERB          126806\n",
       "ADJ            94507\n",
       "ADV            26277\n",
       "ADJ PAST-P     12519\n",
       "Name: WordType, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk TaggedCorpusParses requires uppercase WordType\n",
    "dictcc_df[\"WordType\"] = dictcc_df[\"WordType\"].str.upper()\n",
    "dictcc_df[\"WordType\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add dictcc corpus to our wordlists array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlists.append(dictcc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the corpus from http://icon.shef.ac.uk/Moby/mpos.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform some basic cleanup on the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the readme file in `nltk/corpora/moby/mpos` gives some information on how to parse the file\n",
    "\n",
    "result = []\n",
    "# replace all DOS line endings '\\r' with newlines then change encoding to UTF8\n",
    "moby_words = !cat nltk/corpora/moby/mpos/mobyposi.i | iconv --from-code=ISO88591 --to-code=UTF8 | tr -s '\\r' '\\n' | tr -s '×' '/'\n",
    "result.extend(moby_words)\n",
    "moby_df = pd.DataFrame(data = result, columns = ['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233216</th>\n",
       "      <td>zoomorphic</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233220</th>\n",
       "      <td>zoonal</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233223</th>\n",
       "      <td>zoophagous</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233227</th>\n",
       "      <td>zoophilous</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233229</th>\n",
       "      <td>zoophobous</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233230</th>\n",
       "      <td>zoophoric</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233235</th>\n",
       "      <td>zooplastic</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233333</th>\n",
       "      <td>zygomorphic</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233334</th>\n",
       "      <td>zygophyllaceous</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233342</th>\n",
       "      <td>zymogenic</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Word WordType\n",
       "233216       zoomorphic      ADJ\n",
       "233220           zoonal      ADJ\n",
       "233223       zoophagous      ADJ\n",
       "233227       zoophilous      ADJ\n",
       "233229       zoophobous      ADJ\n",
       "233230        zoophoric      ADJ\n",
       "233235       zooplastic      ADJ\n",
       "233333      zygomorphic      ADJ\n",
       "233334  zygophyllaceous      ADJ\n",
       "233342        zymogenic      ADJ"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sort out the nouns, verbs and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matches nouns\n",
    "nouns = moby_df[moby_df[\"Word\"].str.contains('/[Np]$')].copy()\n",
    "nouns[\"WordType\"] = \"NOUN\"\n",
    "# Matches verbs\n",
    "verbs = moby_df[moby_df[\"Word\"].str.contains('/[Vti]$')].copy()\n",
    "verbs[\"WordType\"] = \"VERB\"\n",
    "# Magtches adjectives\n",
    "adjectives = moby_df[moby_df[\"Word\"].str.contains('/A$')].copy()\n",
    "adjectives[\"WordType\"] = \"ADJ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove the trailing stuff and concatenate the nouns, verbs and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nouns[\"Word\"] = nouns[\"Word\"].str.replace(r'/N$','')\n",
    "verbs[\"Word\"] = verbs[\"Word\"].str.replace(r'/[Vti]$','')\n",
    "adjectives[\"Word\"] = adjectives[\"Word\"].str.replace(r'/A$','')\n",
    "# Merge nouns, verbs and adjectives into one dataframe\n",
    "moby_df = pd.concat([nouns,verbs,adjectives])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add moby corpus to wordlists array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlists.append(moby_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all wordlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlist = pd.concat(wordlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for results that we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove words that aren't associated with a type (null WordType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlist_filtered = wordlist[wordlist[\"WordType\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove words that contain non word characters (whitespace, hypens, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN                  132318\n",
       "VERB                  126665\n",
       "ADJ                    50659\n",
       "ADV                    12748\n",
       "ADJ PAST-P              9327\n",
       "ADJ PRES-P              4223\n",
       "PAST-P                  1291\n",
       "ADJ ADV                  620\n",
       "PREP                     252\n",
       "PRON                     222\n",
       "PRES-P                   173\n",
       "CONJ                     124\n",
       "PAST-P ADJ                33\n",
       "PRES-P ADJ                26\n",
       "ADV PREP                  20\n",
       "ADJ PRON                  16\n",
       "PREFIX                    10\n",
       "ADJ ARCHAIC:ADV           10\n",
       "ADV CONJ                   9\n",
       "PREP CONJ                  5\n",
       "ADJ.                       4\n",
       "ADV ADJ                    4\n",
       "ADV PAST-P                 3\n",
       "[NONE]                     2\n",
       "ADJ ARCHAIC:PAST-P         2\n",
       "ADV DATED:ADJ              2\n",
       "ADV PREP CONJ              2\n",
       "ADJ OBS:PAST-P             1\n",
       "ADJ RARE:ADV               1\n",
       "PRES-P ARCHAIC:ADJ         1\n",
       "ADJ RARE:PAST-P            1\n",
       "ADJ ADV NOUN               1\n",
       "ADJ ADV PREP CONJ          1\n",
       "ADV.                       1\n",
       "ADJ PRED                   1\n",
       "AD JPAST-P                 1\n",
       "ADV PRON                   1\n",
       "ADJ COLL:ADV               1\n",
       "ADV ARCHAIC:ADJ            1\n",
       "PREP ADV                   1\n",
       "PRES-P RARE:ADJ            1\n",
       "ADJ PREP                   1\n",
       "Name: WordType, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we choose [a-z] here and not [A-Za-z] because we do _not_\n",
    "# want to match words starting with uppercase characters.\n",
    "# ^to matches verbs in the infinitive from `dictcc`\n",
    "word_chars = r'^[a-z]+$|^to\\s'\n",
    "is_word_chars = wordlist_filtered[\"Word\"].str.contains(word_chars, na=False)\n",
    "wordlist_filtered = wordlist_filtered[is_word_chars]\n",
    "wordlist_filtered.describe()\n",
    "wordlist_filtered[\"WordType\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  We want results that are less than 'x' letters long (x+3 for verbs since they are in their infinitive form in the dictcc wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108112</td>\n",
       "      <td>108112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>39257</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>boom</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>35</td>\n",
       "      <td>64792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word WordType\n",
       "count   108112   108112\n",
       "unique   39257       39\n",
       "top       boom     NOUN\n",
       "freq        35    64792"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_x_letters = (wordlist_filtered[\"Word\"].str.len() < 9) |\\\n",
    "               ((wordlist_filtered[\"Word\"].str.contains('^to\\s\\w+\\s')) &\\\n",
    "                (wordlist_filtered[\"Word\"].str.len() < 11)\\\n",
    "               )\n",
    "wordlist_filtered = wordlist_filtered[lt_x_letters]\n",
    "wordlist_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove all duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN                  24671\n",
       "ADJ                    6901\n",
       "VERB                   2663\n",
       "ADJ PAST-P             2130\n",
       "ADV                    1250\n",
       "ADJ PRES-P              705\n",
       "PAST-P                  622\n",
       "ADJ ADV                 132\n",
       "PRON                     45\n",
       "PREP                     43\n",
       "PRES-P                   34\n",
       "CONJ                     23\n",
       "PREFIX                    8\n",
       "PAST-P ADJ                8\n",
       "ADJ PRON                  5\n",
       "PRES-P ADJ                4\n",
       "ADJ ARCHAIC:ADV           2\n",
       "ADV CONJ                  2\n",
       "ADJ OBS:PAST-P            1\n",
       "ADV DATED:ADJ             1\n",
       "ADV PREP                  1\n",
       "ADV PRON                  1\n",
       "ADJ ARCHAIC:PAST-P        1\n",
       "PRES-P ARCHAIC:ADJ        1\n",
       "ADV PREP CONJ             1\n",
       "[NONE]                    1\n",
       "ADV ADJ                   1\n",
       "Name: WordType, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist_filtered = wordlist_filtered.drop_duplicates(\"Word\")\n",
    "wordlist_filtered.describe()\n",
    "wordlist_filtered[\"WordType\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our wordlists into nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The TaggedCorpusReader likes to use the forward slash character '/'\n",
    "# as seperator between the word and part-of-speech tag (WordType).\n",
    "wordlist_filtered.to_csv(\"dictcc_moby.csv\",index=False,sep=\"/\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import TaggedCorpusReader\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "nltk_wordlist = TaggedCorpusReader(\"./\", \"dictcc_moby.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use NLTK to help us merge our wordlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Our custom wordlist\n",
    "import nltk\n",
    "custom_cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in nltk_wordlist.tagged_words() if len(word) < 9 and word.isalpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Brown Corpus\n",
    "import nltk\n",
    "brown_cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in nltk.corpus.brown.tagged_words() if word.isalpha() and len(word) < 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nouns count: 31178\n"
     ]
    }
   ],
   "source": [
    "# Merge Nouns from all wordlists\n",
    "nouns = set(brown_cfd[\"NN\"]) | set(brown_cfd[\"NP\"]) | set(custom_cfd[\"NOUN\"])\n",
    "# Lowercase all words to remove duplicates\n",
    "nouns = set([noun.lower() for noun in nouns])\n",
    "print(\"Total nouns count: \" + str(len(nouns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total verbs count: 4991\n"
     ]
    }
   ],
   "source": [
    "# Merge Verbs from all wordlists\n",
    "verbs = set(brown_cfd[\"VB\"]) | set(brown_cfd[\"VBD\"]) | set(custom_cfd[\"VERB\"])\n",
    "# Lowercase all words to remove duplicates\n",
    "verbs = set([verb.lower() for verb in verbs])\n",
    "print(\"Total verbs count: \" + str(len(verbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total adjectives count: 10541\n"
     ]
    }
   ],
   "source": [
    "# Merge Adjectives from all wordlists\n",
    "adjectives = set(brown_cfd[\"JJ\"]) | set(custom_cfd[\"ADJ\"])\n",
    "# Lowercase all words to remove duplicates\n",
    "adjectives = set([adjective.lower() for adjective in adjectives])\n",
    "print(\"Total adjectives count: \" + str(len(adjectives)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Some Placewords Magic Happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def populate_degrees(nouns):\n",
    "    degrees = {}\n",
    "    nouns_copy = nouns.copy()\n",
    "    for latitude in range(60):\n",
    "        for longtitude in range(190):\n",
    "            degrees[(latitude,longtitude)] = nouns_copy.pop()\n",
    "    return degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_minutes(verbs):\n",
    "    minutes = {}\n",
    "    verbs_copy = verbs.copy()\n",
    "    for latitude in range(60):\n",
    "        for longtitude in range(60):\n",
    "            minutes[(latitude,longtitude)] = verbs_copy.pop()\n",
    "    return minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def populate_seconds(adjectives):\n",
    "    seconds = {}\n",
    "    adjectives_copy = adjectives.copy()\n",
    "    for latitude in range(60):\n",
    "        for longtitude in range(60):\n",
    "            seconds[(latitude,longtitude)] = adjectives_copy.pop()\n",
    "    return seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def populate_fractions(nouns):\n",
    "    fractions = {}\n",
    "    nouns_copy = nouns.copy()\n",
    "    for latitude in range(10):\n",
    "        for longtitude in range(10):\n",
    "            fractions[(latitude,longtitude)] = nouns_copy.pop()\n",
    "    return fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def placewords(degrees,minutes,seconds,fractions):\n",
    "    result = []\n",
    "    result.append(populate_degrees(nouns).get(degrees))\n",
    "    result.append(populate_minutes(verbs).get(minutes))\n",
    "    result.append(populate_seconds(adjectives).get(seconds))\n",
    "    result.append(populate_fractions(nouns).get(fractions))\n",
    "    return \"-\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feel free to stalk me at canards-rallied-planked-corium\n"
     ]
    }
   ],
   "source": [
    "# Located at 50°40'47.9\" N 10°55'55.2\" E\n",
    "ilmenau_home = placewords((50,10),(40,55),(47,55),(9,2))\n",
    "print(\"Feel free to stalk me at \" + ilmenau_home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO (wordlist filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove stopwords from wordlist\n",
    "\n",
    "```\n",
    "from nltk.corpus import stopwords\n",
    "dif = set(wordlist_filtered['Word']) - set(stopwords.words('english'))\n",
    "names = nltk.corpus.names\n",
    "names.fileids()\n",
    "```\n",
    "- We want to remove all names and animals\n",
    "\n",
    "- We want to remove words that are difficult to spell\n",
    "\n",
    "   - Words with uncommon vowel duplicates (examples: [\"piing\", \"reeject\"])\n",
    "\n",
    "- We want to remove homonyms that are used in different parts of speech (example: saw (as verb) and saw (as noun))\n",
    "\n",
    "- We want to remove arcane and unusual words\n",
    "\n",
    "```\n",
    "import nltk\n",
    "\n",
    "def unusual_words(text):\n",
    "    text_vocab = set(w.lower() for w in text if w.isalpha())\n",
    "    english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "    unusual = text_vocab - english_vocab\n",
    "    return sorted(unusual)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
