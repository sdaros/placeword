{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our wordlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import all of our wordlists and add them to an array which me can merge at the end. \n",
    "\n",
    "This wordlists should not be filtered at this point. However they should all contain the same columns to make merging easier for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordlists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the dictionary from http://www.dict.cc/?s=about%3Awordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the first 20 lines of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DE-EN vocabulary database\tcompiled by dict.cc\r\n",
      "# Date and time\t2016-08-29 23:46\r\n",
      "# License\tTHIS WORK IS PROTECTED BY INTERNATIONAL COPYRIGHT LAWS!\r\n",
      "# License\tPrivate use is allowed as long as the data, or parts of it, are not published or given away.\r\n",
      "# License\tBy using this file, you agree to be bound to the Terms of Use published at the following URL:  \r\n",
      "# License\thttp://www.dict.cc/translation_file_request.php\r\n",
      "# Contains data from\thttp://dict.tu-chemnitz.de/ with friendly permission by Frank Richter, TU Chemnitz \r\n",
      "# Brought to you by\tPaul Hemetsberger and the users of http://www.dict.cc/, 2002 - 2016\r\n",
      "\r\n",
      "&#945;-Keratin {n}\t&#945;-keratin\tnoun\r\n",
      "&#945;-Lactalbumin {n} <&#945;-La>\t&#945;-lactalbumin <&#945;-La>\tnoun\r\n",
      "&#946;-Mercaptoethanol {n}\t&#946;-mercaptoethanol\tnoun\r\n",
      "&#963;-Algebra {f}\t&#963;-field\tnoun\r\n",
      "&#963;-Algebra {f}\tsigma algebra\tnoun\r\n",
      "& Co.\tand company <& Co.>\t\r\n",
      "'Die' heißt mein Unterrock, und 'der' hängt im Schrank. [regional] [Satz, mit dem Kinder gerügt werden, die von einer (anwesenden) Frau mit 'die' sprechen]\t'She' is the cat's mother. [used to encourage children to use names instead of pronouns to refer to females to whom they should show respect]\t\r\n",
      "'n Abend allerseits! [ugs.]\tEvening all! [coll.]\t\r\n",
      "'nauf [regional] [hinauf]\tup\tadv\r\n",
      "'Nduja {f} [auch: Nduja]\t'nduja [also: nduja]\tnoun\r\n",
      "'ne Macke haben [ugs.]\tto be off one's head [coll.]\tverb\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 20 de-en.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use pandas library to import csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "dictcc_df = pd.read_csv(\"de-en.txt\", \n",
    "                        sep='\\t',\n",
    "                        skiprows=8,\n",
    "                        header=None, \n",
    "                        names=[\"GermanWord\",\"Word\",\"WordType\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview a few entries of the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GermanWord</th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>(aktiv) Werbung machen für</td>\n",
       "      <td>to tout</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>(aktive) Langzeitverbindung {f} [Standverbindu...</td>\n",
       "      <td>nailed-up connection &lt;NUC&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>(aktuelles) Zeitgeschehen {n}</td>\n",
       "      <td>current events {pl}</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>(akustisch) verstehen</td>\n",
       "      <td>to hear</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>(akustische) Haarzelle {f}</td>\n",
       "      <td>auditory cell</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(akustischer) Dissipationsgrad {m}</td>\n",
       "      <td>(acoustic) dissipation factor</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>(akute) Rückenmuskelnekrose {f}</td>\n",
       "      <td>(acute) back muscle necrosis</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(akuter) Hörsturz {m}</td>\n",
       "      <td>acute hearing loss</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(akuter) Myokardinfarkt {m} &lt;AMI / MI&gt;</td>\n",
       "      <td>(acute) myocardial infarction &lt;AMI / MI&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>(akutes) Lungenversagen {n}</td>\n",
       "      <td>acute respiratory distress syndrome &lt;ARDS&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           GermanWord  \\\n",
       "90                         (aktiv) Werbung machen für   \n",
       "91  (aktive) Langzeitverbindung {f} [Standverbindu...   \n",
       "92                      (aktuelles) Zeitgeschehen {n}   \n",
       "93                              (akustisch) verstehen   \n",
       "94                         (akustische) Haarzelle {f}   \n",
       "95                 (akustischer) Dissipationsgrad {m}   \n",
       "96                    (akute) Rückenmuskelnekrose {f}   \n",
       "97                              (akuter) Hörsturz {m}   \n",
       "98             (akuter) Myokardinfarkt {m} <AMI / MI>   \n",
       "99                        (akutes) Lungenversagen {n}   \n",
       "\n",
       "                                          Word WordType  \n",
       "90                                     to tout     verb  \n",
       "91                  nailed-up connection <NUC>     noun  \n",
       "92                         current events {pl}     noun  \n",
       "93                                     to hear     verb  \n",
       "94                               auditory cell     noun  \n",
       "95               (acoustic) dissipation factor     noun  \n",
       "96                (acute) back muscle necrosis     noun  \n",
       "97                          acute hearing loss     noun  \n",
       "98    (acute) myocardial infarction <AMI / MI>     noun  \n",
       "99  acute respiratory distress syndrome <ARDS>     noun  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictcc_df[90:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We only need \"Word\" and \"WordType\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictcc_df = dictcc_df[[\"Word\", \"WordType\"]][:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert WordType Column to a pandas.Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word          object\n",
       "WordType    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_types = dictcc_df[\"WordType\"].astype('category')\n",
    "dictcc_df[\"WordType\"] = word_types\n",
    "# show data types of each column in the dataframe\n",
    "dictcc_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the current distribution of word types in dictcc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noun          759619\n",
       "verb          126806\n",
       "adj            94507\n",
       "adv            26277\n",
       "adj past-p     12519\n",
       "Name: WordType, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictcc_df[\"WordType\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add dictcc corpus to our wordlists array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlists.append(dictcc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the corpus from http://icon.shef.ac.uk/Moby/mpos.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform some basic cleanup on the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the readme file in `nltk/corpora/moby/mpos` gives some information on how to parse the file\n",
    "\n",
    "result = []\n",
    "# replace all DOS line endings '\\r' with newlines then change encoding to UTF8\n",
    "moby_words = !cat nltk/corpora/moby/mpos/mobyposi.i | iconv --from-code=ISO88591 --to-code=UTF8 | tr -s '\\r' '\\n' | tr -s '×' '/'\n",
    "result.extend(moby_words)\n",
    "moby_df = pd.DataFrame(data = result, columns = ['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-D/AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4-F/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4-H'er/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-H/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A battery/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a bon march/v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a cappella/Av</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a capriccio/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a datu/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a fortiori/v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a gogo/Av</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A horizon/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a la carte/Av</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a la king/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a la mode/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a la/P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A level/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a posteriori/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a priori/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a punta d'arco/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a quo/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a rivederci/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A supply/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a tempo/Avh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>a tergo/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a vinculo matrimonii/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>a vol/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>a'/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A-1/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A-axis/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233326</th>\n",
       "      <td>Zworykin/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233327</th>\n",
       "      <td>zygapophysis/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233328</th>\n",
       "      <td>zygodactyl/AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233329</th>\n",
       "      <td>zygomatic arch/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233330</th>\n",
       "      <td>zygomatic bone/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233331</th>\n",
       "      <td>zygomatic process/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233332</th>\n",
       "      <td>zygoma/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233333</th>\n",
       "      <td>zygomorphic/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233334</th>\n",
       "      <td>zygophyllaceous/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233335</th>\n",
       "      <td>zygophyte/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233336</th>\n",
       "      <td>zygosis/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233337</th>\n",
       "      <td>zygospore/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233338</th>\n",
       "      <td>zygotene/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233339</th>\n",
       "      <td>zygote/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233340</th>\n",
       "      <td>zymase/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233341</th>\n",
       "      <td>zymogenesis/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233342</th>\n",
       "      <td>zymogenic/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233343</th>\n",
       "      <td>zymogen/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233344</th>\n",
       "      <td>zymology/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233345</th>\n",
       "      <td>zymolysis/NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233346</th>\n",
       "      <td>zymometer/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233347</th>\n",
       "      <td>zymosis/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233348</th>\n",
       "      <td>Zyrian/NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233349</th>\n",
       "      <td>Zysk/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233350</th>\n",
       "      <td>zZt/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233351</th>\n",
       "      <td>Zz/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233352</th>\n",
       "      <td>ZZ/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233353</th>\n",
       "      <td>Zllner/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233354</th>\n",
       "      <td>Z/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233355</th>\n",
       "      <td>z/N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233356 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Word\n",
       "0                       3-D/AN\n",
       "1                        4-F/N\n",
       "2                     4-H'er/N\n",
       "3                        4-H/A\n",
       "4                  A battery/h\n",
       "5                a bon march/v\n",
       "6                a cappella/Av\n",
       "7                a capriccio/h\n",
       "8                     a datu/h\n",
       "9                 a fortiori/v\n",
       "10                   a gogo/Av\n",
       "11                 A horizon/h\n",
       "12               a la carte/Av\n",
       "13                 a la king/A\n",
       "14                 a la mode/A\n",
       "15                      a la/P\n",
       "16                   A level/h\n",
       "17              a posteriori/A\n",
       "18                  a priori/A\n",
       "19            a punta d'arco/h\n",
       "20                     a quo/h\n",
       "21               a rivederci/h\n",
       "22                  A supply/h\n",
       "23                 a tempo/Avh\n",
       "24                   a tergo/h\n",
       "25      a vinculo matrimonii/h\n",
       "26                     a vol/h\n",
       "27                        a'/A\n",
       "28                       A-1/N\n",
       "29                    A-axis/N\n",
       "...                        ...\n",
       "233326              Zworykin/N\n",
       "233327          zygapophysis/N\n",
       "233328           zygodactyl/AN\n",
       "233329        zygomatic arch/h\n",
       "233330        zygomatic bone/h\n",
       "233331     zygomatic process/h\n",
       "233332                zygoma/N\n",
       "233333           zygomorphic/A\n",
       "233334       zygophyllaceous/A\n",
       "233335             zygophyte/N\n",
       "233336               zygosis/N\n",
       "233337             zygospore/N\n",
       "233338              zygotene/N\n",
       "233339                zygote/N\n",
       "233340                zymase/N\n",
       "233341           zymogenesis/N\n",
       "233342             zymogenic/A\n",
       "233343               zymogen/N\n",
       "233344              zymology/N\n",
       "233345            zymolysis/NA\n",
       "233346             zymometer/N\n",
       "233347               zymosis/N\n",
       "233348               Zyrian/NA\n",
       "233349                  Zysk/N\n",
       "233350                   zZt/N\n",
       "233351                    Zz/N\n",
       "233352                    ZZ/N\n",
       "233353               Zllner/N\n",
       "233354                     Z/N\n",
       "233355                     z/N\n",
       "\n",
       "[233356 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sort out the nouns, verbs and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matches nouns\n",
    "nouns = moby_df[moby_df[\"Word\"].str.contains('/[Np]$')].copy()\n",
    "nouns[\"WordType\"] = \"noun\"\n",
    "# Matches verbs\n",
    "verbs = moby_df[moby_df[\"Word\"].str.contains('/[Vti]$')].copy()\n",
    "verbs[\"WordType\"] = \"verb\"\n",
    "# Magtches adjectives\n",
    "adjectives = moby_df[moby_df[\"Word\"].str.contains('/A$')].copy()\n",
    "adjectives[\"WordType\"] = \"adj\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove the trailing stuff and concatenate the nouns, verbs and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nouns[\"Word\"] = nouns[\"Word\"].str.replace(r'/N$','')\n",
    "verbs[\"Word\"] = verbs[\"Word\"].str.replace(r'/[Vti]$','')\n",
    "adjectives[\"Word\"] = adjectives[\"Word\"].str.replace(r'/A$','')\n",
    "# Merge nouns, verbs and adjectives into one dataframe\n",
    "moby_df = pd.concat([nouns,verbs,adjectives])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add moby corpus to wordlists array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlists.append(moby_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brown (from nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- We can probably work with `nltk.corpus.brown.tagged_words()` when creating our dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all wordlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1277915</td>\n",
       "      <td>1203402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>923477</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>depression</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>36</td>\n",
       "      <td>867851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word WordType\n",
       "count      1277915  1203402\n",
       "unique      923477       62\n",
       "top     depression     noun\n",
       "freq            36   867851"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = pd.concat(wordlists)\n",
    "wordlist.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for results that we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove words that contain non word characters (whitespace, hypens, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>326484</td>\n",
       "      <td>324632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>166915</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>depression</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>36</td>\n",
       "      <td>188966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word WordType\n",
       "count       326484   324632\n",
       "unique      166915       40\n",
       "top     depression     noun\n",
       "freq            36   188966"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we choose [a-z] here and not [A-Za-z] because we do _not_\n",
    "# want to match words starting with uppercase characters.\n",
    "word_chars = r'^[a-z]+$'\n",
    "is_word_chars = wordlist[\"Word\"].str.contains(word_chars, na=False)\n",
    "wordlist_filtered = wordlist[is_word_chars]\n",
    "wordlist_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  We want results that are less than 'x' letters long (x+3 for verbs since they are in their infinitive form in the dictcc wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139647</td>\n",
       "      <td>138790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>59722</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>boom</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>35</td>\n",
       "      <td>88092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word WordType\n",
       "count   139647   138790\n",
       "unique   59722       38\n",
       "top       boom     noun\n",
       "freq        35    88092"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_x_letters = (wordlist_filtered[\"Word\"].str.len() < 9) |\\\n",
    "               ((wordlist_filtered[\"Word\"].str.contains('^to\\s\\w+\\s')) &\\\n",
    "                (wordlist_filtered[\"Word\"].str.len() < 11)\\\n",
    "               )\n",
    "wordlist_filtered = wordlist_filtered[lt_x_letters]\n",
    "wordlist_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove all duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59722</td>\n",
       "      <td>59244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>59722</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>pluteus</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>37176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word WordType\n",
       "count     59722    59244\n",
       "unique    59722       26\n",
       "top     pluteus     noun\n",
       "freq          1    37176"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist_filtered = wordlist_filtered.drop_duplicates(\"Word\")\n",
    "wordlist_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove words that are difficult to spell\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Words with uncommon vowel duplicates (examples: [\"piing\", \"reeject\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove all names and animals\n",
    "\n",
    "TODO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- We want to remove stopwords from wordlist\n",
    "\n",
    "```\n",
    "from nltk.corpus import stopwords\n",
    "dif = set(wordlist_filtered['Word']) - set(stopwords.words('english'))\n",
    "names = nltk.corpus.names\n",
    "names.fileids()\n",
    "```\n",
    "\n",
    "- We want to remove homonyms that are used in different parts of speech (example: saw (as verb) and saw (as noun))\n",
    "\n",
    "- We want to remove arcane and unusual words\n",
    "\n",
    "```\n",
    "import nltk\n",
    "\n",
    "def unusual_words(text):\n",
    "    text_vocab = set(w.lower() for w in text if w.isalpha())\n",
    "    english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "    unusual = text_vocab - english_vocab\n",
    "    return sorted(unusual)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximize distance between neighbouring words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nouns like \"cobra\" and \"domra\" should not be located at Geo-Coordinate \"55°x11°\" and \"55°x12°\"\n",
    "- TODO: the spread_words() method doesn't actually solve this problem. We will need to update it by calculating the distance to **all 8** of its adjacent neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# `pip install python-levenshtein`\n",
    "# used to calculate the Levenshtein distance between words\n",
    "import Levenshtein as lev\n",
    "\n",
    "# Maximize the Levenshtein distance between neighbouring words\n",
    "def spread_words(dataframe_values, min_distance = 25, min_lev = 5):\n",
    "    words = []\n",
    "    words.extend(dataframe_values)\n",
    "    short_distances = 0\n",
    "    for i in range(len(words)-1):\n",
    "        next = i + 1\n",
    "        if lev.distance(words[i],words[next]) < min_lev:\n",
    "            short_distances = short_distances + 1\n",
    "            words.append(words[next])\n",
    "            words.remove(words[next])\n",
    "    # The value for min_distance was derived\n",
    "    # by simple trial and error\n",
    "    if short_distances < min_distance:\n",
    "        # The remaining words with short distance \n",
    "        # will have to be sorted out by hand.\n",
    "        return words\n",
    "    else:\n",
    "        # Recurse until we minimize short distances\n",
    "        # as much as possible.\n",
    "        return spread_words(words)\n",
    "\n",
    "# Insert distance of neighbour\n",
    "def insert_neighbour_distance(words):\n",
    "    result = []\n",
    "    word_with_neighbour_distance = ()\n",
    "    for i in range(len(words)-1):\n",
    "        next = i + 1\n",
    "        lev_distance = lev.distance(words[i],words[next])\n",
    "        word_with_neighbour_distance = words[i], lev_distance\n",
    "        result.append(word_with_neighbour_distance)\n",
    "    return pd.DataFrame(data = result, columns=['Words', 'NeighbourDistance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>NeighbourDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vimana</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bookfair</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guacin</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hedgehog</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capsomer</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>frigger</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>otitis</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bakeware</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>repic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>narwhal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  NeighbourDistance\n",
       "0    vimana                  7\n",
       "1  bookfair                  7\n",
       "2    guacin                  8\n",
       "3  hedgehog                  8\n",
       "4  capsomer                  6\n",
       "5   frigger                  6\n",
       "6    otitis                  8\n",
       "7  bakeware                  7\n",
       "8     repic                  6\n",
       "9   narwhal                  7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = wordlist_filtered[wordlist_filtered[\"WordType\"] == \"noun\"]\n",
    "# randomize for better performance\n",
    "nouns = nouns.sample(len(nouns))\n",
    "min_distance_nouns = spread_words(nouns[\"Word\"].values,50,3)\n",
    "nouns_ready_for_export = insert_neighbour_distance(min_distance_nouns)\n",
    "nouns_ready_for_export[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>NeighbourDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vimana</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bookfair</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guacin</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hedgehog</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capsomer</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>frigger</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>otitis</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bakeware</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>repic</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>narwhal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  NeighbourDistance\n",
       "0    vimana                  7\n",
       "1  bookfair                  7\n",
       "2    guacin                  8\n",
       "3  hedgehog                  8\n",
       "4  capsomer                  6\n",
       "5   frigger                  6\n",
       "6    otitis                  8\n",
       "7  bakeware                  7\n",
       "8     repic                  6\n",
       "9   narwhal                  7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjectives = wordlist_filtered[wordlist_filtered[\"WordType\"] == \"adj\"]\n",
    "# randomize for better performance\n",
    "adjectives = adjectives.sample(len(adjectives))\n",
    "min_distance_adjectives = spread_words(nouns[\"Word\"].values,50,3)\n",
    "adjectives_ready_for_export = insert_neighbour_distance(min_distance_adjectives)\n",
    "adjectives_ready_for_export[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>NeighbourDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>impair</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exerted</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stitched</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abscise</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wared</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exhort</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>maligned</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>detached</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>upbuilt</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rehone</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  NeighbourDistance\n",
       "0    impair                  7\n",
       "1   exerted                  6\n",
       "2  stitched                  7\n",
       "3   abscise                  7\n",
       "4     wared                  6\n",
       "5    exhort                  8\n",
       "6  maligned                  6\n",
       "7  detached                  8\n",
       "8   upbuilt                  7\n",
       "9    rehone                  5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use \"adj past-p\" as verbs conjugated in the past tense until \n",
    "# we use nltk to properly conjugate all verbs in our wordlist\n",
    "verbs_init = wordlist_filtered[((wordlist_filtered[\"WordType\"] == \"adj past-p\") | (wordlist_filtered[\"WordType\"] == \"verb\"))]\n",
    "verbs = verbs_init.sample(n=len(verbs_init))\n",
    "min_distance_verbs = spread_words(verbs[\"Word\"].values,50,3)\n",
    "verbs_ready_for_export = insert_neighbour_distance(min_distance_verbs)\n",
    "verbs_ready_for_export[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the distribution of word types after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noun          37176\n",
       "adj           12177\n",
       "verb           4913\n",
       "adj past-p     2126\n",
       "adv            1232\n",
       "Name: WordType, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist_filtered[\"WordType\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export our filtered word lists to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nouns_ready_for_export.to_csv(\"nouns.csv\", index=False)\n",
    "adjectives_ready_for_export.to_csv(\"adjectives.csv\", index=False)\n",
    "verbs_ready_for_export.to_csv(\"verbs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highroad handled pilaf titania\n"
     ]
    }
   ],
   "source": [
    "print(nouns_ready_for_export.sample()['Words'].values[0] + ' ' +\\\n",
    "      verbs_ready_for_export.sample()['Words'].values[0] + ' ' +\\\n",
    "      adjectives_ready_for_export.sample()['Words'].values[0] + ' ' +\\\n",
    "      nouns_ready_for_export.sample()['Words'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource 'corpora/brown' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/home/sd/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/sd/DLCI/p/dev/virtualenvs/testing/lib/python3.5/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'corpora/%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sd/DLCI/p/dev/virtualenvs/testing/lib/python3.5/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/brown.zip/brown/' not found.  Please use the\n  NLTK Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/home/sd/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-99d5b1d4ab7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbrown\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbrown_news_tagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagged_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'news'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'universal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtag_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbrown_news_tagged\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtag_fd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sd/DLCI/p/dev/virtualenvs/testing/lib/python3.5/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sd/DLCI/p/dev/virtualenvs/testing/lib/python3.5/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'corpora/%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sd/DLCI/p/dev/virtualenvs/testing/lib/python3.5/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'corpora/%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'corpora/%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sd/DLCI/p/dev/virtualenvs/testing/lib/python3.5/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/brown' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/home/sd/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged if len(word) < 9)\n",
    "tag_fd.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wsj = nltk.corpus.treebank.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfd2 = nltk.ConditionalFreqDist(wsj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# given that we have word 'foobar' with which tag\n",
    "# does it appear most often?\n",
    "\n",
    "[word for word in cfd1.conditions() if 'VBD' in cfd1[word] and 'VBN' in cfd1[word]]\n",
    "idx1 = wsj.index(('followed', 'VBN'))\n",
    "wsj[idx1-4:idx1+4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "past_participles = [w for w in cfd2 if 'VBN' in cfd2[w]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Show common words for particular parts-of-speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_common_words(tagged_text):\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text)\n",
    "    return dict((tag, cfd[tag].most_common()) for tag in cfd.conditions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 1547),\n",
       " ('man', 1144),\n",
       " ('Af', 990),\n",
       " ('way', 882),\n",
       " ('world', 682),\n",
       " ('life', 673),\n",
       " ('year', 641),\n",
       " ('day', 623),\n",
       " ('work', 571),\n",
       " ('state', 519),\n",
       " ('place', 473),\n",
       " ('course', 464),\n",
       " ('number', 461),\n",
       " ('part', 460),\n",
       " ('fact', 446),\n",
       " ('water', 420),\n",
       " ('hand', 410),\n",
       " ('school', 409),\n",
       " ('head', 403),\n",
       " ('night', 398),\n",
       " ('system', 392),\n",
       " ('house', 387),\n",
       " ('group', 377),\n",
       " ('room', 364),\n",
       " ('program', 363),\n",
       " ('side', 363),\n",
       " ('end', 358),\n",
       " ('business', 355),\n",
       " ('case', 349),\n",
       " ('use', 348),\n",
       " ('point', 348),\n",
       " ('order', 342),\n",
       " ('thing', 326),\n",
       " ('power', 321),\n",
       " ('interest', 319),\n",
       " ('face', 319),\n",
       " ('area', 318),\n",
       " ('door', 312),\n",
       " ('country', 311),\n",
       " ('family', 310),\n",
       " ('problem', 309),\n",
       " ('development', 306),\n",
       " ('war', 300),\n",
       " ('sense', 300),\n",
       " ('form', 299),\n",
       " ('kind', 295),\n",
       " ('mind', 287),\n",
       " ('example', 286),\n",
       " ('action', 286),\n",
       " ('matter', 281),\n",
       " ('line', 279),\n",
       " ('law', 277),\n",
       " ('car', 269),\n",
       " ('body', 269),\n",
       " ('government', 269),\n",
       " ('history', 268),\n",
       " ('period', 263),\n",
       " ('death', 262),\n",
       " ('word', 259),\n",
       " ('money', 258),\n",
       " ('city', 257),\n",
       " ('information', 257),\n",
       " ('name', 256),\n",
       " ('week', 256),\n",
       " ('experience', 254),\n",
       " ('light', 251),\n",
       " ('moment', 244),\n",
       " ('field', 240),\n",
       " ('service', 240),\n",
       " ('reason', 236),\n",
       " ('position', 233),\n",
       " ('job', 233),\n",
       " ('boy', 232),\n",
       " ('question', 231),\n",
       " ('wife', 227),\n",
       " ('church', 222),\n",
       " ('voice', 220),\n",
       " ('company', 217),\n",
       " ('home', 217),\n",
       " ('woman', 216),\n",
       " ('policy', 216),\n",
       " ('air', 216),\n",
       " ('office', 214),\n",
       " ('community', 212),\n",
       " ('age', 212),\n",
       " ('girl', 211),\n",
       " ('child', 209),\n",
       " ('morning', 208),\n",
       " ('rate', 205),\n",
       " ('study', 200),\n",
       " ('evidence', 200),\n",
       " ('town', 198),\n",
       " ('effect', 197),\n",
       " ('value', 197),\n",
       " ('result', 196),\n",
       " ('situation', 196),\n",
       " ('level', 194),\n",
       " ('music', 194),\n",
       " ('society', 192),\n",
       " ('process', 191),\n",
       " ('surface', 191),\n",
       " ('type', 190),\n",
       " ('idea', 190),\n",
       " ('mother', 190),\n",
       " ('party', 189),\n",
       " ('land', 187),\n",
       " ('century', 183),\n",
       " ('basis', 183),\n",
       " ('nature', 182),\n",
       " ('pressure', 181),\n",
       " ('tax', 180),\n",
       " ('control', 179),\n",
       " ('road', 178),\n",
       " ('art', 177),\n",
       " ('attention', 177),\n",
       " ('back', 176),\n",
       " ('cost', 176),\n",
       " ('center', 175),\n",
       " ('book', 175),\n",
       " ('force', 173),\n",
       " ('education', 171),\n",
       " ('heart', 170),\n",
       " ('person', 170),\n",
       " ('stage', 169),\n",
       " ('space', 169),\n",
       " ('ground', 168),\n",
       " ('material', 166),\n",
       " ('view', 165),\n",
       " ('board', 164),\n",
       " ('plan', 164),\n",
       " ('love', 161),\n",
       " ('equipment', 161),\n",
       " ('class', 161),\n",
       " ('college', 160),\n",
       " ('spirit', 160),\n",
       " ('change', 160),\n",
       " ('fire', 159),\n",
       " ('father', 159),\n",
       " ('picture', 159),\n",
       " ('industry', 158),\n",
       " ('floor', 157),\n",
       " ('sort', 156),\n",
       " ('cent', 155),\n",
       " ('need', 153),\n",
       " ('growth', 150),\n",
       " ('paper', 150),\n",
       " ('story', 148),\n",
       " ('property', 148),\n",
       " ('difference', 147),\n",
       " ('figure', 147),\n",
       " ('hair', 147),\n",
       " ('street', 146),\n",
       " ('table', 146),\n",
       " ('purpose', 145),\n",
       " ('hour', 145),\n",
       " ('effort', 145),\n",
       " ('knowledge', 143),\n",
       " ('front', 142),\n",
       " ('statement', 141),\n",
       " ('amount', 141),\n",
       " ('production', 140),\n",
       " ('market', 140),\n",
       " ('addition', 140),\n",
       " ('range', 140),\n",
       " ('son', 139),\n",
       " ('letter', 139),\n",
       " ('wall', 137),\n",
       " ('rest', 135),\n",
       " ('public', 135),\n",
       " ('stock', 135),\n",
       " ('population', 135),\n",
       " ('food', 134),\n",
       " ('member', 133),\n",
       " ('size', 133),\n",
       " ('future', 132),\n",
       " ('direction', 132),\n",
       " ('section', 132),\n",
       " ('literature', 131),\n",
       " ('strength', 131),\n",
       " ('summer', 131),\n",
       " ('feeling', 131),\n",
       " ('peace', 131),\n",
       " ('husband', 131),\n",
       " ('method', 130),\n",
       " ('color', 130),\n",
       " ('month', 130),\n",
       " ('top', 129),\n",
       " ('issue', 129),\n",
       " ('total', 129),\n",
       " ('temperature', 128),\n",
       " ('evening', 128),\n",
       " ('piece', 127),\n",
       " ('research', 127),\n",
       " ('trouble', 127),\n",
       " ('theory', 126),\n",
       " ('chance', 126),\n",
       " ('bed', 126),\n",
       " ('sound', 126),\n",
       " ('defense', 125),\n",
       " ('list', 125),\n",
       " ('friend', 125),\n",
       " ('degree', 125),\n",
       " ('president', 125),\n",
       " ('manner', 124),\n",
       " ('truth', 123),\n",
       " ('lot', 123),\n",
       " ('movement', 123),\n",
       " ('record', 123),\n",
       " ('performance', 122),\n",
       " ('right', 122),\n",
       " ('support', 122),\n",
       " ('meeting', 122),\n",
       " ('trade', 121),\n",
       " ('subject', 121),\n",
       " ('treatment', 121),\n",
       " ('game', 121),\n",
       " ('couple', 121),\n",
       " ('window', 119),\n",
       " ('freedom', 119),\n",
       " ('decision', 119),\n",
       " ('reaction', 119),\n",
       " ('eye', 119),\n",
       " ('opportunity', 119),\n",
       " ('nation', 118),\n",
       " ('respect', 118),\n",
       " ('character', 117),\n",
       " ('trial', 116),\n",
       " ('plant', 116),\n",
       " ('responsibility', 115),\n",
       " ('earth', 115),\n",
       " ('image', 115),\n",
       " ('audience', 115),\n",
       " ('labor', 114),\n",
       " ('report', 114),\n",
       " ('volume', 114),\n",
       " ('blood', 114),\n",
       " ('activity', 113),\n",
       " ('court', 113),\n",
       " ('corner', 113),\n",
       " ('series', 113),\n",
       " ('length', 113),\n",
       " ('influence', 112),\n",
       " ('quality', 112),\n",
       " ('increase', 112),\n",
       " ('meaning', 112),\n",
       " ('plane', 111),\n",
       " ('extent', 110),\n",
       " ('pattern', 110),\n",
       " ('horse', 109),\n",
       " ('step', 109),\n",
       " ('importance', 108),\n",
       " ('student', 108),\n",
       " ('farm', 107),\n",
       " ('function', 107),\n",
       " ('distance', 107),\n",
       " ('answer', 106),\n",
       " ('language', 106),\n",
       " ('Aj', 106),\n",
       " ('hall', 106),\n",
       " ('principle', 106),\n",
       " ('organization', 106),\n",
       " ('season', 105),\n",
       " ('afternoon', 105),\n",
       " ('existence', 105),\n",
       " ('science', 105),\n",
       " ('attitude', 105),\n",
       " ('design', 104),\n",
       " ('pool', 104),\n",
       " ('approach', 104),\n",
       " ('choice', 104),\n",
       " ('operation', 104),\n",
       " ('charge', 104),\n",
       " ('role', 104),\n",
       " ('progress', 104),\n",
       " ('mouth', 103),\n",
       " ('return', 103),\n",
       " ('administration', 103),\n",
       " ('thought', 103),\n",
       " ('radio', 103),\n",
       " ('scene', 102),\n",
       " ('ball', 101),\n",
       " ('faith', 101),\n",
       " ('aid', 101),\n",
       " ('spring', 101),\n",
       " ('sun', 101),\n",
       " ('religion', 100),\n",
       " ('staff', 100),\n",
       " ('will', 99),\n",
       " ('analysis', 99),\n",
       " ('past', 98),\n",
       " ('price', 98),\n",
       " ('machine', 98),\n",
       " ('gun', 98),\n",
       " ('hope', 97),\n",
       " ('date', 97),\n",
       " ('style', 97),\n",
       " ('glass', 96),\n",
       " ('stress', 96),\n",
       " ('doubt', 96),\n",
       " ('look', 96),\n",
       " ('income', 95),\n",
       " ('lack', 95),\n",
       " ('behavior', 95),\n",
       " ('officer', 95),\n",
       " ('unit', 94),\n",
       " ('status', 94),\n",
       " ('energy', 94),\n",
       " ('opinion', 94),\n",
       " ('race', 94),\n",
       " ('building', 94),\n",
       " ('fear', 93),\n",
       " ('bit', 93),\n",
       " ('test', 93),\n",
       " ('tradition', 92),\n",
       " ('station', 92),\n",
       " ('gas', 92),\n",
       " ('help', 92),\n",
       " ('act', 92),\n",
       " ('arm', 91),\n",
       " ('marriage', 91),\n",
       " ('film', 91),\n",
       " ('weight', 90),\n",
       " ('source', 90),\n",
       " ('radiation', 90),\n",
       " ('university', 90),\n",
       " ('dinner', 90),\n",
       " ('kitchen', 90),\n",
       " ('leadership', 89),\n",
       " ('deal', 89),\n",
       " ('turn', 88),\n",
       " ('play', 88),\n",
       " ('discussion', 87),\n",
       " ('doctor', 87),\n",
       " ('oil', 87),\n",
       " ('structure', 87),\n",
       " ('construction', 87),\n",
       " ('health', 87),\n",
       " ('account', 87),\n",
       " ('enemy', 87),\n",
       " ('pain', 87),\n",
       " ('news', 87),\n",
       " ('relationship', 87),\n",
       " ('possibility', 87),\n",
       " ('set', 86),\n",
       " ('condition', 86),\n",
       " ('success', 85),\n",
       " ('heat', 85),\n",
       " ('management', 85),\n",
       " ('care', 84),\n",
       " ('loss', 84),\n",
       " ('clay', 84),\n",
       " ('variety', 84),\n",
       " ('concern', 84),\n",
       " ('hotel', 83),\n",
       " ('failure', 83),\n",
       " ('authority', 83),\n",
       " ('beginning', 83),\n",
       " ('capacity', 83),\n",
       " ('training', 83),\n",
       " ('concept', 83),\n",
       " ('poetry', 82),\n",
       " ('instance', 82),\n",
       " ('understanding', 82),\n",
       " ('collection', 82),\n",
       " ('assistance', 82),\n",
       " ('sight', 82),\n",
       " ('individual', 81),\n",
       " ('event', 81),\n",
       " ('sex', 81),\n",
       " ('team', 81),\n",
       " ('jazz', 81),\n",
       " ('philosophy', 81),\n",
       " ('mass', 80),\n",
       " ('balance', 80),\n",
       " ('press', 80),\n",
       " ('product', 80),\n",
       " ('committee', 80),\n",
       " ('agreement', 79),\n",
       " ('bridge', 79),\n",
       " ('atmosphere', 79),\n",
       " ('practice', 79),\n",
       " ('project', 79),\n",
       " ('manager', 79),\n",
       " ('apartment', 79),\n",
       " ('while', 78),\n",
       " ('bill', 78),\n",
       " ('expression', 78),\n",
       " ('trip', 78),\n",
       " ('reality', 78),\n",
       " ('sea', 78),\n",
       " ('distribution', 77),\n",
       " ('session', 77),\n",
       " ('union', 77),\n",
       " ('cause', 77),\n",
       " ('teacher', 77),\n",
       " ('bottom', 77),\n",
       " ('attack', 77),\n",
       " ('river', 77),\n",
       " ('district', 77),\n",
       " ('director', 76),\n",
       " ('difficulty', 76),\n",
       " ('bottle', 76),\n",
       " ('response', 76),\n",
       " ('crisis', 76),\n",
       " ('shape', 76),\n",
       " ('winter', 76),\n",
       " ('demand', 76),\n",
       " ('capital', 76),\n",
       " ('base', 76),\n",
       " ('edge', 76),\n",
       " ('neck', 76),\n",
       " ('ship', 76),\n",
       " ('presence', 75),\n",
       " ('police', 75),\n",
       " ('justice', 75),\n",
       " ('economy', 75),\n",
       " ('patient', 75),\n",
       " ('anode', 75),\n",
       " ('memory', 75),\n",
       " ('battle', 75),\n",
       " ('campaign', 75),\n",
       " ('hospital', 75),\n",
       " ('term', 75),\n",
       " ('coffee', 74),\n",
       " ('ability', 74),\n",
       " ('security', 74),\n",
       " ('means', 74),\n",
       " ('index', 74),\n",
       " ('data', 74),\n",
       " ('square', 74),\n",
       " ('speed', 73),\n",
       " ('sign', 73),\n",
       " ('advantage', 73),\n",
       " ('tone', 73),\n",
       " ('youth', 72),\n",
       " ('note', 72),\n",
       " ('knife', 72),\n",
       " ('election', 72),\n",
       " ('faculty', 72),\n",
       " ('attempt', 71),\n",
       " ('hell', 71),\n",
       " ('region', 71),\n",
       " ('procedure', 71),\n",
       " ('brother', 71),\n",
       " ('show', 71),\n",
       " ('writer', 71),\n",
       " ('dog', 70),\n",
       " ('detail', 70),\n",
       " ('corporation', 70),\n",
       " ('factor', 70),\n",
       " ('daughter', 70),\n",
       " ('platform', 70),\n",
       " ('fall', 70),\n",
       " ('frame', 69),\n",
       " ('club', 69),\n",
       " ('claim', 69),\n",
       " ('C', 68),\n",
       " ('county', 68),\n",
       " ('address', 68),\n",
       " ('poet', 68),\n",
       " ('murder', 68),\n",
       " ('contrast', 68),\n",
       " ('desire', 68),\n",
       " ('connection', 68),\n",
       " ('foot', 68),\n",
       " ('animal', 68),\n",
       " ('boat', 68),\n",
       " ('career', 67),\n",
       " ('bar', 67),\n",
       " ('beauty', 67),\n",
       " ('danger', 67),\n",
       " ('train', 67),\n",
       " ('reference', 66),\n",
       " ('wine', 66),\n",
       " ('impact', 66),\n",
       " ('unity', 66),\n",
       " ('relief', 66),\n",
       " ('weather', 66),\n",
       " ('leader', 66),\n",
       " ('dust', 65),\n",
       " ('significance', 65),\n",
       " ('division', 65),\n",
       " ('store', 65),\n",
       " ('desk', 65),\n",
       " ('imagination', 65),\n",
       " ('dance', 65),\n",
       " ('background', 65),\n",
       " ('rain', 64),\n",
       " ('membership', 64),\n",
       " ('politics', 64),\n",
       " ('chair', 64),\n",
       " ('box', 64),\n",
       " ('cell', 64),\n",
       " ('phase', 64),\n",
       " ('protection', 64),\n",
       " ('camp', 64),\n",
       " ('communication', 64),\n",
       " ('shelter', 63),\n",
       " ('application', 63),\n",
       " ('telephone', 63),\n",
       " ('message', 63),\n",
       " ('site', 63),\n",
       " ('universe', 63),\n",
       " ('belief', 63),\n",
       " ('fashion', 63),\n",
       " ('argument', 63),\n",
       " ('portion', 62),\n",
       " ('jury', 62),\n",
       " ('newspaper', 62),\n",
       " ('relation', 62),\n",
       " ('mission', 62),\n",
       " ('speech', 61),\n",
       " ('department', 61),\n",
       " ('conference', 61),\n",
       " ('fellow', 61),\n",
       " ('block', 61),\n",
       " ('measure', 60),\n",
       " ('machinery', 60),\n",
       " ('page', 60),\n",
       " ('good', 60),\n",
       " ('shot', 60),\n",
       " ('resolution', 60),\n",
       " ('location', 60),\n",
       " ('goal', 60),\n",
       " ('visit', 59),\n",
       " ('nose', 59),\n",
       " ('average', 59),\n",
       " ('traffic', 59),\n",
       " ('rifle', 59),\n",
       " ('column', 59),\n",
       " ('firm', 59),\n",
       " ('rule', 58),\n",
       " ('assignment', 58),\n",
       " ('task', 58),\n",
       " ('shoulder', 58),\n",
       " ('search', 58),\n",
       " ('duty', 58),\n",
       " ('emphasis', 58),\n",
       " ('occasion', 58),\n",
       " ('aircraft', 58),\n",
       " ('pleasure', 58),\n",
       " ('roof', 58),\n",
       " ('judgment', 58),\n",
       " ('model', 57),\n",
       " ('majority', 57),\n",
       " ('feed', 57),\n",
       " ('conclusion', 57),\n",
       " ('achievement', 57),\n",
       " ('combination', 57),\n",
       " ('appearance', 57),\n",
       " ('baby', 57),\n",
       " ('metal', 57),\n",
       " ('culture', 56),\n",
       " ('song', 56),\n",
       " ('maintenance', 56),\n",
       " ('tree', 56),\n",
       " ('drink', 56),\n",
       " ('share', 56),\n",
       " ('solution', 56),\n",
       " ('intensity', 56),\n",
       " ('sky', 56),\n",
       " ('formula', 56),\n",
       " ('entrance', 56),\n",
       " ('army', 56),\n",
       " ('favor', 55),\n",
       " ('technique', 55),\n",
       " ('exchange', 55),\n",
       " ('struggle', 55),\n",
       " ('item', 55),\n",
       " ('neighborhood', 55),\n",
       " ('identity', 55),\n",
       " ('vision', 55),\n",
       " ('theme', 55),\n",
       " ('circle', 55),\n",
       " ('competition', 55),\n",
       " ('flow', 55),\n",
       " ('post', 55),\n",
       " ('confidence', 54),\n",
       " ('motion', 54),\n",
       " ('victory', 54),\n",
       " ('truck', 54),\n",
       " ('wind', 54),\n",
       " ('artist', 54),\n",
       " ('tension', 54),\n",
       " ('symbol', 54),\n",
       " ('fight', 54),\n",
       " ('text', 54),\n",
       " ('touch', 54),\n",
       " ('kid', 54),\n",
       " ('hat', 54),\n",
       " ('bank', 54),\n",
       " ('supply', 54),\n",
       " ('dictionary', 54),\n",
       " ('rise', 53),\n",
       " ('device', 53),\n",
       " ('leg', 53),\n",
       " ('seat', 53),\n",
       " ('percent', 53),\n",
       " ('dress', 53),\n",
       " ('objective', 53),\n",
       " ('absence', 53),\n",
       " ('taste', 53),\n",
       " ('generation', 53),\n",
       " ('wage', 53),\n",
       " ('contact', 53),\n",
       " ('hole', 53),\n",
       " ('contract', 53),\n",
       " ('credit', 53),\n",
       " ('regard', 53),\n",
       " ('depth', 53),\n",
       " ('budget', 53),\n",
       " ('chest', 53),\n",
       " ('reading', 52),\n",
       " ('grass', 52),\n",
       " ('signal', 52),\n",
       " ('baseball', 52),\n",
       " ('disease', 52),\n",
       " ('wagon', 52),\n",
       " ('bedroom', 52),\n",
       " ('scale', 52),\n",
       " ('establishment', 52),\n",
       " ('flesh', 52),\n",
       " ('object', 52),\n",
       " ('dozen', 52),\n",
       " ('description', 52),\n",
       " ('run', 52),\n",
       " ('element', 52),\n",
       " ('spot', 52),\n",
       " ('wheel', 52),\n",
       " ('experiment', 52),\n",
       " ('wood', 51),\n",
       " ('rock', 51),\n",
       " ('title', 51),\n",
       " ('motor', 51),\n",
       " ('breakfast', 51),\n",
       " ('approval', 51),\n",
       " ('sample', 51),\n",
       " ('pair', 50),\n",
       " ('score', 50),\n",
       " ('payment', 50),\n",
       " ('start', 50),\n",
       " ('angle', 50),\n",
       " ('expense', 50),\n",
       " ('snow', 50),\n",
       " ('breath', 50),\n",
       " ('conviction', 50),\n",
       " ('crowd', 50),\n",
       " ('conversation', 50),\n",
       " ('whole', 50),\n",
       " ('sin', 50),\n",
       " ('interpretation', 50),\n",
       " ('publication', 49),\n",
       " ('television', 49),\n",
       " ('stream', 49),\n",
       " ('tendency', 49),\n",
       " ('key', 49),\n",
       " ('master', 49),\n",
       " ('A', 49),\n",
       " ('advice', 49),\n",
       " ('operator', 49),\n",
       " ('childhood', 49),\n",
       " ('shop', 49),\n",
       " ('soil', 49),\n",
       " ('call', 49),\n",
       " ('consideration', 49),\n",
       " ('dream', 48),\n",
       " ('conflict', 48),\n",
       " ('poem', 48),\n",
       " ('estate', 48),\n",
       " ('comparison', 48),\n",
       " ('acceptance', 48),\n",
       " ('lady', 48),\n",
       " ('appeal', 48),\n",
       " ('novel', 48),\n",
       " ('spite', 48),\n",
       " ('command', 48),\n",
       " ('vote', 48),\n",
       " ('chairman', 48),\n",
       " ('smile', 48),\n",
       " ('gain', 48),\n",
       " ('agency', 48),\n",
       " ('driver', 48),\n",
       " ('valley', 48),\n",
       " ('passage', 48),\n",
       " ('drive', 48),\n",
       " ('lead', 47),\n",
       " ('railroad', 47),\n",
       " ('testimony', 47),\n",
       " ('honor', 47),\n",
       " ('stone', 47),\n",
       " ('skin', 47),\n",
       " ('library', 47),\n",
       " ('soul', 47),\n",
       " ('birth', 47),\n",
       " ('efficiency', 47),\n",
       " ('version', 47),\n",
       " ('engine', 47),\n",
       " ('integration', 47),\n",
       " ('hearing', 47),\n",
       " ('village', 47),\n",
       " ('phone', 47),\n",
       " ('aspect', 47),\n",
       " ('detective', 47),\n",
       " ('hero', 46),\n",
       " ('association', 46),\n",
       " ('decade', 46),\n",
       " ('missile', 46),\n",
       " ('middle', 46),\n",
       " ('vacation', 46),\n",
       " ('anger', 46),\n",
       " ('moon', 46),\n",
       " ('garden', 46),\n",
       " ('tragedy', 46),\n",
       " ('percentage', 46),\n",
       " ('silence', 46),\n",
       " ('artery', 46),\n",
       " ('personality', 46),\n",
       " ('article', 46),\n",
       " ('fiction', 46),\n",
       " ('chain', 46),\n",
       " ('provision', 46),\n",
       " ('park', 46),\n",
       " ('concentration', 46),\n",
       " ('welfare', 45),\n",
       " ('target', 45),\n",
       " ('safety', 45),\n",
       " ('congregation', 45),\n",
       " ('luck', 45),\n",
       " ('weakness', 45),\n",
       " ('sheet', 45),\n",
       " ('curve', 45),\n",
       " ('impression', 45),\n",
       " ('opposition', 45),\n",
       " ('expansion', 45),\n",
       " ('trend', 45),\n",
       " ('independence', 45),\n",
       " ('minister', 45),\n",
       " ('agent', 44),\n",
       " ('band', 44),\n",
       " ('employment', 44),\n",
       " ('creation', 44),\n",
       " ('captain', 44),\n",
       " ('surprise', 44),\n",
       " ('preparation', 44),\n",
       " ('file', 44),\n",
       " ('path', 44),\n",
       " ('present', 44),\n",
       " ('instrument', 44),\n",
       " ('sale', 44),\n",
       " ('legislation', 44),\n",
       " ('milk', 44),\n",
       " ('intelligence', 44),\n",
       " ('dollar', 43),\n",
       " ('ice', 43),\n",
       " ('precision', 43),\n",
       " ('environment', 43),\n",
       " ('oxygen', 43),\n",
       " ('sum', 43),\n",
       " ('darkness', 43),\n",
       " ('meat', 43),\n",
       " ('drama', 43),\n",
       " ('lawyer', 43),\n",
       " ('confusion', 43),\n",
       " ('investigation', 43),\n",
       " ('violence', 43),\n",
       " ('wave', 43),\n",
       " ('planning', 43),\n",
       " ('plenty', 43),\n",
       " ('editor', 43),\n",
       " ('thickness', 43),\n",
       " ('humor', 43),\n",
       " ('recognition', 43),\n",
       " ('reader', 43),\n",
       " ('diameter', 43),\n",
       " ('resistance', 43),\n",
       " ('flight', 43),\n",
       " ('minute', 43),\n",
       " ('fun', 43),\n",
       " ('cup', 43),\n",
       " ('burden', 43),\n",
       " ('mile', 42),\n",
       " ('request', 42),\n",
       " ('liquor', 42),\n",
       " ('warfare', 42),\n",
       " ('coat', 42),\n",
       " ('risk', 42),\n",
       " ('porch', 42),\n",
       " ('brain', 42),\n",
       " ('revolution', 42),\n",
       " ('guy', 42),\n",
       " ('bond', 42),\n",
       " ('wisdom', 42),\n",
       " ('load', 42),\n",
       " ('identification', 42),\n",
       " ('cloth', 42),\n",
       " ('interference', 42),\n",
       " ('snake', 42),\n",
       " ('weapon', 42),\n",
       " ('pocket', 42),\n",
       " ('origin', 42),\n",
       " ('dirt', 42),\n",
       " ('author', 42),\n",
       " ('screen', 42),\n",
       " ('explanation', 42),\n",
       " ('benefit', 42),\n",
       " ('mold', 42),\n",
       " ('governor', 41),\n",
       " ('bag', 41),\n",
       " ('loan', 41),\n",
       " ('storage', 41),\n",
       " ('automobile', 41),\n",
       " ('wire', 41),\n",
       " ('fund', 41),\n",
       " ('distinction', 41),\n",
       " ('salary', 41),\n",
       " ('content', 41),\n",
       " ('advance', 41),\n",
       " ('salt', 41),\n",
       " ('tissue', 41),\n",
       " ('comfort', 41),\n",
       " ('bread', 40),\n",
       " ('notion', 40),\n",
       " ('joy', 40),\n",
       " ('orchestra', 40),\n",
       " ('throat', 40),\n",
       " ('forest', 40),\n",
       " ('talk', 40),\n",
       " ('proposal', 40),\n",
       " ('reduction', 40),\n",
       " ('skill', 40),\n",
       " ('arc', 40),\n",
       " ('finger', 40),\n",
       " ('liberty', 40),\n",
       " ('shore', 40),\n",
       " ('exception', 40),\n",
       " ('removal', 40),\n",
       " ('core', 40),\n",
       " ('suit', 40),\n",
       " ('prison', 40),\n",
       " ('long-range', 40),\n",
       " ('insurance', 40),\n",
       " ('pilot', 40),\n",
       " ('inch', 39),\n",
       " ('allotment', 39),\n",
       " ('secretary', 39),\n",
       " ('talent', 39),\n",
       " ('pride', 39),\n",
       " ('thinking', 39),\n",
       " ('Q', 39),\n",
       " ('participation', 39),\n",
       " ('necessity', 39),\n",
       " ('transportation', 39),\n",
       " ('threat', 39),\n",
       " ('shear', 38),\n",
       " ('seed', 38),\n",
       " ('criticism', 38),\n",
       " ('doctrine', 38),\n",
       " ('muscle', 38),\n",
       " ('tour', 38),\n",
       " ('editorial', 38),\n",
       " ('steel', 38),\n",
       " ('determination', 38),\n",
       " ('investment', 38),\n",
       " ('pay', 38),\n",
       " ('soldier', 38),\n",
       " ('assumption', 38),\n",
       " ('theater', 38),\n",
       " ('selection', 38),\n",
       " ('institution', 38),\n",
       " ('stand', 38),\n",
       " ('hydrogen', 38),\n",
       " ('communism', 38),\n",
       " ('guidance', 38),\n",
       " ('pace', 37),\n",
       " ('civilization', 37),\n",
       " ('furniture', 37),\n",
       " ('writing', 37),\n",
       " ('stomach', 37),\n",
       " ('tool', 37),\n",
       " ('restaurant', 37),\n",
       " ('comedy', 37),\n",
       " ('atom', 37),\n",
       " ('improvement', 37),\n",
       " ('chapter', 37),\n",
       " ('conscience', 37),\n",
       " ('anxiety', 37),\n",
       " ('switch', 37),\n",
       " ('headquarters', 37),\n",
       " ('stranger', 37),\n",
       " ('formation', 37),\n",
       " ('destruction', 37),\n",
       " ('gold', 36),\n",
       " ('foam', 36),\n",
       " ('move', 36),\n",
       " ('contribution', 36),\n",
       " ('profession', 36),\n",
       " ('recreation', 36),\n",
       " ('host', 36),\n",
       " ('mystery', 36),\n",
       " ('medium', 36),\n",
       " ('chemical', 36),\n",
       " ('completion', 36),\n",
       " ('mankind', 36),\n",
       " ('cooperation', 36),\n",
       " ('mark', 36),\n",
       " ('hill', 36),\n",
       " ('maturity', 36),\n",
       " ('engineer', 36),\n",
       " ('check', 36),\n",
       " ('edition', 36),\n",
       " ('illusion', 36),\n",
       " ('intention', 36),\n",
       " ('thyroid', 36),\n",
       " ('crew', 36),\n",
       " ('promise', 36),\n",
       " ('copy', 36),\n",
       " ('executive', 36),\n",
       " ('noise', 35),\n",
       " ('mail', 35),\n",
       " ('grade', 35),\n",
       " ('review', 35),\n",
       " ('accuracy', 35),\n",
       " ('exercise', 35),\n",
       " ('human', 35),\n",
       " ('output', 35),\n",
       " ('tongue', 35),\n",
       " ('outlook', 35),\n",
       " ('award', 35),\n",
       " ('phenomenon', 35),\n",
       " ('T', 35),\n",
       " ('probability', 35),\n",
       " ('license', 35),\n",
       " ('concert', 35),\n",
       " ('coating', 35),\n",
       " ('iron', 35),\n",
       " ('sequence', 35),\n",
       " ('consumer', 35),\n",
       " ('mood', 35),\n",
       " ('marine', 35),\n",
       " ('incident', 35),\n",
       " ('height', 34),\n",
       " ('pencil', 34),\n",
       " ('definition', 34),\n",
       " ('sympathy', 34),\n",
       " ('cover', 34),\n",
       " ('ratio', 34),\n",
       " ('scholarship', 34),\n",
       " ('myth', 34),\n",
       " ('technology', 34),\n",
       " ('reception', 34),\n",
       " ('sister', 34),\n",
       " ('axis', 34),\n",
       " ('emotion', 34),\n",
       " ('self', 34),\n",
       " ('track', 34),\n",
       " ('dignity', 34),\n",
       " ('bus', 34),\n",
       " ('comment', 34),\n",
       " ('schedule', 34),\n",
       " ('candidate', 34),\n",
       " ('error', 34),\n",
       " ('nationalism', 34),\n",
       " ('sake', 34),\n",
       " ('conduct', 34),\n",
       " ('camera', 34),\n",
       " ('guest', 34),\n",
       " ('yard', 33),\n",
       " ('equation', 33),\n",
       " ('clerk', 33),\n",
       " ('bone', 33),\n",
       " ('extension', 33),\n",
       " ('sentence', 33),\n",
       " ('TV', 33),\n",
       " ('desegregation', 33),\n",
       " ('ring', 33),\n",
       " ('bomb', 33),\n",
       " ('sleep', 33),\n",
       " ('admission', 33),\n",
       " ('owner', 33),\n",
       " ('beach', 33),\n",
       " ('discovery', 33),\n",
       " ('suggestion', 33),\n",
       " ('scheme', 33),\n",
       " ('guilt', 33),\n",
       " ('chlorine', 33),\n",
       " ('context', 33),\n",
       " ('patent', 33),\n",
       " ('evil', 33),\n",
       " ('sir', 33),\n",
       " ('folk', 33),\n",
       " ('jacket', 33),\n",
       " ('gate', 33),\n",
       " ('arrangement', 33),\n",
       " ('questionnaire', 33),\n",
       " ('sugar', 33),\n",
       " ('affair', 33),\n",
       " ('knee', 33),\n",
       " ('walk', 33),\n",
       " ('emergency', 33),\n",
       " ('quantity', 33),\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "tagdict = find_common_words(nltk.corpus.brown.tagged_words())\n",
    "# only nouns (that is, don't include proper nouns)\n",
    "tagdict['NN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
