{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our wordlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import all of our wordlists and add them to an array which me can merge at the end. \n",
    "\n",
    "This wordlists should not be filtered at this point. However they should all contain the same columns to make merging easier for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordlists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the dictionary from http://www.dict.cc/?s=about%3Awordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the first 20 lines of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DE-EN vocabulary database\tcompiled by dict.cc\r\n",
      "# Date and time\t2016-08-29 23:46\r\n",
      "# License\tTHIS WORK IS PROTECTED BY INTERNATIONAL COPYRIGHT LAWS!\r\n",
      "# License\tPrivate use is allowed as long as the data, or parts of it, are not published or given away.\r\n",
      "# License\tBy using this file, you agree to be bound to the Terms of Use published at the following URL:  \r\n",
      "# License\thttp://www.dict.cc/translation_file_request.php\r\n",
      "# Contains data from\thttp://dict.tu-chemnitz.de/ with friendly permission by Frank Richter, TU Chemnitz \r\n",
      "# Brought to you by\tPaul Hemetsberger and the users of http://www.dict.cc/, 2002 - 2016\r\n",
      "\r\n",
      "&#945;-Keratin {n}\t&#945;-keratin\tnoun\r\n",
      "&#945;-Lactalbumin {n} <&#945;-La>\t&#945;-lactalbumin <&#945;-La>\tnoun\r\n",
      "&#946;-Mercaptoethanol {n}\t&#946;-mercaptoethanol\tnoun\r\n",
      "&#963;-Algebra {f}\t&#963;-field\tnoun\r\n",
      "&#963;-Algebra {f}\tsigma algebra\tnoun\r\n",
      "& Co.\tand company <& Co.>\t\r\n",
      "'Die' heißt mein Unterrock, und 'der' hängt im Schrank. [regional] [Satz, mit dem Kinder gerügt werden, die von einer (anwesenden) Frau mit 'die' sprechen]\t'She' is the cat's mother. [used to encourage children to use names instead of pronouns to refer to females to whom they should show respect]\t\r\n",
      "'n Abend allerseits! [ugs.]\tEvening all! [coll.]\t\r\n",
      "'nauf [regional] [hinauf]\tup\tadv\r\n",
      "'Nduja {f} [auch: Nduja]\t'nduja [also: nduja]\tnoun\r\n",
      "'ne Macke haben [ugs.]\tto be off one's head [coll.]\tverb\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 20 de-en.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use pandas library to import csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "dictcc_df = pd.read_csv(\"de-en.txt\", \n",
    "                        sep='\\t',\n",
    "                        skiprows=8,\n",
    "                        header=None, \n",
    "                        names=[\"GermanWord\",\"Word\",\"WordType\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview a few entries of the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GermanWord</th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>(aktiv) Werbung machen für</td>\n",
       "      <td>to tout</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>(aktive) Langzeitverbindung {f} [Standverbindu...</td>\n",
       "      <td>nailed-up connection &lt;NUC&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>(aktuelles) Zeitgeschehen {n}</td>\n",
       "      <td>current events {pl}</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>(akustisch) verstehen</td>\n",
       "      <td>to hear</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>(akustische) Haarzelle {f}</td>\n",
       "      <td>auditory cell</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(akustischer) Dissipationsgrad {m}</td>\n",
       "      <td>(acoustic) dissipation factor</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>(akute) Rückenmuskelnekrose {f}</td>\n",
       "      <td>(acute) back muscle necrosis</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(akuter) Hörsturz {m}</td>\n",
       "      <td>acute hearing loss</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(akuter) Myokardinfarkt {m} &lt;AMI / MI&gt;</td>\n",
       "      <td>(acute) myocardial infarction &lt;AMI / MI&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>(akutes) Lungenversagen {n}</td>\n",
       "      <td>acute respiratory distress syndrome &lt;ARDS&gt;</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           GermanWord  \\\n",
       "90                         (aktiv) Werbung machen für   \n",
       "91  (aktive) Langzeitverbindung {f} [Standverbindu...   \n",
       "92                      (aktuelles) Zeitgeschehen {n}   \n",
       "93                              (akustisch) verstehen   \n",
       "94                         (akustische) Haarzelle {f}   \n",
       "95                 (akustischer) Dissipationsgrad {m}   \n",
       "96                    (akute) Rückenmuskelnekrose {f}   \n",
       "97                              (akuter) Hörsturz {m}   \n",
       "98             (akuter) Myokardinfarkt {m} <AMI / MI>   \n",
       "99                        (akutes) Lungenversagen {n}   \n",
       "\n",
       "                                          Word WordType  \n",
       "90                                     to tout     verb  \n",
       "91                  nailed-up connection <NUC>     noun  \n",
       "92                         current events {pl}     noun  \n",
       "93                                     to hear     verb  \n",
       "94                               auditory cell     noun  \n",
       "95               (acoustic) dissipation factor     noun  \n",
       "96                (acute) back muscle necrosis     noun  \n",
       "97                          acute hearing loss     noun  \n",
       "98    (acute) myocardial infarction <AMI / MI>     noun  \n",
       "99  acute respiratory distress syndrome <ARDS>     noun  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictcc_df[90:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We only need \"Word\" and \"WordType\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictcc_df = dictcc_df[[\"Word\", \"WordType\"]][:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert WordType Column to a pandas.Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word          object\n",
       "WordType    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_types = dictcc_df[\"WordType\"].astype('category')\n",
    "dictcc_df[\"WordType\"] = word_types\n",
    "# show data types of each column in the dataframe\n",
    "dictcc_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the current distribution of word types in dictcc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noun          759619\n",
       "verb          126806\n",
       "adj            94507\n",
       "adv            26277\n",
       "adj past-p     12519\n",
       "Name: WordType, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictcc_df[\"WordType\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add dictcc corpus to our wordlists array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlists.append(dictcc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the corpus from http://icon.shef.ac.uk/Moby/mpos.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform some basic cleanup on the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the readme file in `nltk/corpora/moby/mpos` gives some information on how to parse the file\n",
    "\n",
    "result = []\n",
    "# replace all DOS line endings '\\r' with newlines then change encoding to UTF8\n",
    "moby_words = !cat nltk/corpora/moby/mpos/mobyposi.i | tr -s '\\r' '\\n' | iconv --from-code=ISO88591 --to-code=UTF8\n",
    "result.extend(moby_words)\n",
    "moby_df = pd.DataFrame(data = result, columns = ['Word'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sort out the nouns, verbs and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matches nouns\n",
    "nouns = moby_df[moby_df[\"Word\"].str.contains('×[Np]$')].copy()\n",
    "nouns[\"WordType\"] = \"noun\"\n",
    "# Matches verbs\n",
    "verbs = moby_df[moby_df[\"Word\"].str.contains('×[Vti]$')].copy()\n",
    "verbs[\"WordType\"] = \"verb\"\n",
    "# Magtches adjectives\n",
    "adjectives = moby_df[moby_df[\"Word\"].str.contains('×A$')].copy()\n",
    "adjectives[\"WordType\"] = \"adj\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove the trailing stuff and concatenate the nouns, verbs and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nouns[\"Word\"] = nouns[\"Word\"].str.replace(r'×N$','')\n",
    "verbs[\"Word\"] = verbs[\"Word\"].str.replace(r'×[Vti]$','')\n",
    "adjectives[\"Word\"] = adjectives[\"Word\"].str.replace(r'×A$','')\n",
    "# Merge nouns, verbs and adjectives into one dataframe\n",
    "moby_df = pd.concat([nouns,verbs,adjectives])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add moby corpus to wordlists array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlists.append(moby_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all wordlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1277915</td>\n",
       "      <td>1203402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>923477</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>depression</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>36</td>\n",
       "      <td>867851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word WordType\n",
       "count      1277915  1203402\n",
       "unique      923477       62\n",
       "top     depression     noun\n",
       "freq            36   867851"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = pd.concat(wordlists)\n",
    "wordlist.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for results that we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove words that contain non word characters (whitespace, hypens, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>326484</td>\n",
       "      <td>324632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>166915</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>depression</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>36</td>\n",
       "      <td>188966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word WordType\n",
       "count       326484   324632\n",
       "unique      166915       40\n",
       "top     depression     noun\n",
       "freq            36   188966"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we choose [a-z] here and not [A-Za-z] because we do _not_\n",
    "# want to match words starting with uppercase characters.\n",
    "word_chars = r'^[a-z]+$'\n",
    "is_word_chars = wordlist[\"Word\"].str.contains(word_chars, na=False)\n",
    "wordlist_filtered = wordlist[is_word_chars]\n",
    "wordlist_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  We want results that are less than 'x' letters long (x+3 for verbs since they are in their infinitive form in the dictcc wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139647</td>\n",
       "      <td>138790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>59722</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>boom</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>35</td>\n",
       "      <td>88092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word WordType\n",
       "count   139647   138790\n",
       "unique   59722       38\n",
       "top       boom     noun\n",
       "freq        35    88092"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_x_letters = (wordlist_filtered[\"Word\"].str.len() < 9) |\\\n",
    "               ((wordlist_filtered[\"Word\"].str.contains('^to\\s\\w+\\s')) &\\\n",
    "                (wordlist_filtered[\"Word\"].str.len() < 11)\\\n",
    "               )\n",
    "wordlist_filtered = wordlist_filtered[lt_x_letters]\n",
    "wordlist_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove all duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>WordType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59722</td>\n",
       "      <td>59244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>59722</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>unstably</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>37176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word WordType\n",
       "count      59722    59244\n",
       "unique     59722       26\n",
       "top     unstably     noun\n",
       "freq           1    37176"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist_filtered = wordlist_filtered.drop_duplicates(\"Word\")\n",
    "wordlist_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove words that are difficult to spell\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Words with uncommon vowel duplicates (examples: [\"piing\", \"reeject\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to remove all names and animals\n",
    "\n",
    "TODO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to use nltk to perform some more advanced filtering\n",
    "\n",
    "TODO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximize distance between neighbouring words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nouns like \"cobra\" and \"domra\" should not be located at Geo-Coordinate \"55°x11°\" and \"55°x12°\"\n",
    "- TODO: the spread_words() method doesn't actually solve this problem. We will need to update it by calculating the distance to **all 8** of its adjacent neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# `pip install python-levenshtein`\n",
    "# used to calculate the Levenshtein distance between words\n",
    "import Levenshtein as lev\n",
    "\n",
    "# Maximize the Levenshtein distance between neighbouring words\n",
    "def spread_words(dataframe_values, min_distance = 25, min_lev = 5):\n",
    "    words = []\n",
    "    words.extend(dataframe_values)\n",
    "    short_distances = 0\n",
    "    for i in range(len(words)-1):\n",
    "        next = i + 1\n",
    "        if lev.distance(words[i],words[next]) < min_lev:\n",
    "            short_distances = short_distances + 1\n",
    "            words.append(words[next])\n",
    "            words.remove(words[next])\n",
    "    # The value for min_distance was derived\n",
    "    # by simple trial and error\n",
    "    if short_distances < min_distance:\n",
    "        # The remaining words with short distance \n",
    "        # will have to be sorted out by hand.\n",
    "        return words\n",
    "    else:\n",
    "        # Recurse until we minimize short distances\n",
    "        # as much as possible.\n",
    "        return spread_words(words)\n",
    "\n",
    "# Insert distance of neighbour\n",
    "def insert_neighbour_distance(words):\n",
    "    result = []\n",
    "    word_with_neighbour_distance = ()\n",
    "    for i in range(len(words)-1):\n",
    "        next = i + 1\n",
    "        lev_distance = lev.distance(words[i],words[next])\n",
    "        word_with_neighbour_distance = words[i], lev_distance\n",
    "        result.append(word_with_neighbour_distance)\n",
    "    return pd.DataFrame(data = result, columns=['Words', 'NeighbourDistance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>NeighbourDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excud</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clast</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manpages</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hype</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>torments</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grimes</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ending</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>logs</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>furore</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yerba</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  NeighbourDistance\n",
       "0     excud                  5\n",
       "1     clast                  7\n",
       "2  manpages                  6\n",
       "3      hype                  7\n",
       "4  torments                  5\n",
       "5    grimes                  6\n",
       "6    ending                  6\n",
       "7      logs                  5\n",
       "8    furore                  5\n",
       "9     yerba                  7"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = wordlist_filtered[wordlist_filtered[\"WordType\"] == \"noun\"]\n",
    "# randomize for better performance\n",
    "nouns = nouns.sample(len(nouns))\n",
    "min_distance_nouns = spread_words(nouns[\"Word\"].values,50,3)\n",
    "nouns_ready_for_export = insert_neighbour_distance(min_distance_nouns)\n",
    "nouns_ready_for_export[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>NeighbourDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excud</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clast</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manpages</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hype</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>torments</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grimes</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ending</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>logs</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>furore</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yerba</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  NeighbourDistance\n",
       "0     excud                  5\n",
       "1     clast                  7\n",
       "2  manpages                  6\n",
       "3      hype                  7\n",
       "4  torments                  5\n",
       "5    grimes                  6\n",
       "6    ending                  6\n",
       "7      logs                  5\n",
       "8    furore                  5\n",
       "9     yerba                  7"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjectives = wordlist_filtered[wordlist_filtered[\"WordType\"] == \"adj\"]\n",
    "# randomize for better performance\n",
    "adjectives = adjectives.sample(len(adjectives))\n",
    "min_distance_adjectives = spread_words(nouns[\"Word\"].values,50,3)\n",
    "adjectives_ready_for_export = insert_neighbour_distance(min_distance_adjectives)\n",
    "adjectives_ready_for_export[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>NeighbourDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pupping</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>presaged</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>piing</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outboast</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>replume</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pupated</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>copped</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reeject</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hemmed</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prebeset</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  NeighbourDistance\n",
       "0   pupping                  7\n",
       "1  presaged                  6\n",
       "2     piing                  8\n",
       "3  outboast                  8\n",
       "4   replume                  6\n",
       "5   pupated                  4\n",
       "6    copped                  6\n",
       "7   reeject                  5\n",
       "8    hemmed                  6\n",
       "9  prebeset                  7"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use \"adj past-p\" as verbs conjugated in the past tense until \n",
    "# we use nltk to properly conjugate all verbs in our wordlist\n",
    "verbs_init = wordlist_filtered[((wordlist_filtered[\"WordType\"] == \"adj past-p\") | (wordlist_filtered[\"WordType\"] == \"verb\"))]\n",
    "verbs = verbs_init.sample(n=len(verbs_init))\n",
    "min_distance_verbs = spread_words(verbs[\"Word\"].values,50,3)\n",
    "verbs_ready_for_export = insert_neighbour_distance(min_distance_verbs)\n",
    "verbs_ready_for_export[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the distribution of word types after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noun          37176\n",
       "adj           12177\n",
       "verb           4913\n",
       "adj past-p     2126\n",
       "adv            1232\n",
       "Name: WordType, dtype: int64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist_filtered[\"WordType\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export our filtered word lists to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nouns_ready_for_export.to_csv(\"nouns.csv\", index=False)\n",
    "adjectives_ready_for_export.to_csv(\"adjectives.csv\", index=False)\n",
    "verbs_ready_for_export.to_csv(\"verbs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obesity prearm autogyro hechsher\n"
     ]
    }
   ],
   "source": [
    "print(nouns_ready_for_export.sample()['Words'].values[0] + ' ' +\\\n",
    "      verbs_ready_for_export.sample()['Words'].values[0] + ' ' +\\\n",
    "      adjectives_ready_for_export.sample()['Words'].values[0] + ' ' +\\\n",
    "      nouns_ready_for_export.sample()['Words'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
